{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import namedtuple\n",
    "import gensim.parsing.preprocessing as processing\n",
    "import CustomApi as api\n",
    "#Start Global Variables and Types\n",
    "#Number of topics the model should index\n",
    "numberOfTopics = 125\n",
    "#Number of passes the model should make\n",
    "passes = 10\n",
    "#MyAbstract(title:String, date:datetime.datetime, text:String)\n",
    "MyAbstract = namedtuple('MyAbstract',[\"title\",\"date\",\"text\"])\n",
    "#End Global Variables and Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = open(\"../data/paperTable.tsv\",\"r\")\n",
    "entries = []\n",
    "for line in table:\n",
    "    entries.append(line.split('\\t'))\n",
    "table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of frequent words\n",
    "stopFile = open(\"../data/stopwords.txt\",\"r\")\n",
    "stopWords = stopFile.read().splitlines()\n",
    "stopWords.append(\"\\xc2\\xa9\") #This is the copyright symbol, this shows up in every abstract and should not be apart of the corpus\n",
    "stopWords.extend([\"\\u2019\",\"\\u03bc\",\"bee\",\"bees\",\"honey\",\"honeybee\",\"honeybees\"])\n",
    "stopList = set(stopWords)\n",
    "with open(\"../data/extraStopWords.txt\",\"r\") as extraStopFile:\n",
    "    stopWords.extend(extraStopFile.read().split(\"\\n\"))\n",
    "# Lowercase each document, split it by white space and filter out stopWords\n",
    "processing.STOPWORDS = stopWords\n",
    "def removeStops(text):\n",
    "    return processing.remove_stopwords(text.lower().translate(None, string.punctuation))\n",
    "# Each abstract has a 'title':String, 'date':datetime.datetime, and 'text':String\n",
    "abstracts = [MyAbstract._make([art[0],datetime.strptime(art[4][:-1], '%Y-%m-%d'),removeStops((art[1]+art[2]+art[3]))]) for art in entries]\n",
    "abstracts.sort(key=lambda q: q.date.year)\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for abst in abstracts:\n",
    "    for token in abst[2].split(\" \"):\n",
    "        frequency[token] += 1\n",
    "processedCorpus = [[token for token in abst[2].split(\" \") if frequency[token] > 5] for abst in abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary of tokens\n",
    "tempFolder = tempfile.gettempdir()\n",
    "dictionary = corpora.Dictionary(processedCorpus)\n",
    "dictionary.save(os.path.join(tempFolder,'words.dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create general corpus and serialize in order for it to be iterated over\n",
    "corpus = [dictionary.doc2bow(text) for text in processedCorpus]\n",
    "corpora.MmCorpus.serialize(os.path.join(tempFolder, 'words.dict'), corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above corpus shows the amount of times every word used in the documents is used in every indevidual document. Every word is represented by a token ID, the list of which can be found in \"words.dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and set number of topics\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "lda = models.ldamodel.LdaModel(corpus,id2word=dictionary,num_topics=numberOfTopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the most interesting words per topic per document\n",
    "# This cell does not need to be run if only trying to create Top Nine terms per paper\n",
    "topicOrganizingFile = open(\"../data/topicorganization.tsv\",\"w\")\n",
    "for x in xrange(0,len(abstracts)):\n",
    "    doc = dictionary.doc2bow(abstracts[x].split())\n",
    "    docTopics, wordTopics, phiValues = lda.get_document_topics(doc, per_word_topics=True)\n",
    "    topicOrganizingFile.write(yearOfAbstract[x]+\"\\t\"+titleOfAbstract[x]+\"\\t\")\n",
    "    for y in xrange(0,min(3,len(docTopics))):\n",
    "        topicnumber = docTopics[y][0]\n",
    "        topicOrganizingFile.write(str(lda.show_topic(topicnumber))+\"\\t\")\n",
    "        #Sorts the word topics in decending order based on their greatest phi value\n",
    "        for z in xrange(0,len(phiValues)):\n",
    "            phiValues[z][1].sort(key=lambda q:q[1],reverse=True)\n",
    "        phiValues.sort(key=lambda q:q[1][0][1],reverse=True)\n",
    "        curindex=0\n",
    "        topwords = \"\"\n",
    "        for z in xrange(0,3):\n",
    "            while curindex<len(phiValues) and phiValues[curindex][1][0][0]!=topicnumber:\n",
    "                curindex+=1\n",
    "            if(curindex>=len(phiValues)):break\n",
    "            print len(phiValues)\n",
    "            print dictionary[phiValues[curindex][0]]\n",
    "            topwords+=str(dictionary[phiValues[curindex][0]].encode('utf-8').strip())+\" \"\n",
    "            curindex+=1\n",
    "        filter(lambda a:a[0]!=topicnumber,phiValues)\n",
    "        topicOrganizingFile.write(topwords+\"\\t\")\n",
    "    topicOrganizingFile.write(\"\\n\")\n",
    "topicOrganizingFile.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicWords = []\n",
    "for i in range(0,numberOfTopics):\n",
    "    t = lda.get_topic_terms(i,50)\n",
    "    currentWordList = []\n",
    "    for x in t:\n",
    "        word = str(dictionary[x[0]])\n",
    "        if word not in currentWordList:\n",
    "            currentWordList.append(word)\n",
    "    topicWords.append(currentWordList)\n",
    "topicListFile = open(\"../data/TopicWords/List-\"+str(numberOfTopics)+\".txt\",\"w+\")\n",
    "for i in range(0,len(topicWords)):\n",
    "    topicListFile.write(\"Topic \"+str(i)+\":\\n\")\n",
    "    for j in topicWords[i]:\n",
    "        topicListFile.write(j+'\\n')\n",
    "    topicListFile.write('\\n')\n",
    "topicListFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes the top nine terms for each document\n",
    "\n",
    "topNineFile = open(\"../data/Docbow/TopNineTerms-\"+str(numberOfTopics)+\".tsv\",\"w\")\n",
    "for abstr in abstracts:\n",
    "    doc = dictionary.doc2bow(abstracts[2].split()) # Convert to bag of words format first\n",
    "    # Get the topics and words associated with each document\n",
    "    docTopics, wordTopics, phiValues = lda.get_document_topics(doc, per_word_topics=True)\n",
    "    topNineFile.write(yearOfAbstract[x]+\"\\t\"+abst+\"\\t\")\n",
    "    for z in xrange(0,len(phiValues)):\n",
    "        phiValues[z][1].sort(key=lambda q:q[1],reverse=True)\n",
    "    phiValues.sort(key=lambda q:q[1][0][1],reverse=True)\n",
    "    nineWords = \"\"\n",
    "    for x in phiValues[:15]:\n",
    "        nineWords+= dictionary[x[0]] + \" \"\n",
    "    topNineFile.write(nineWords.encode('utf-8')+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the top 5 topics and top 3 words per topic\n",
    "with open(\"../data/Docbow/Top5TopicsTop3WordsTop=\"+str(numberOfTopics)+\".tsv\",\"w\") as file:\n",
    "    docs = [dictionary.doc2bow(a.split()) for a in abstracts] # Convert to bag of words format first\n",
    "    for d in xrange(0,len(docs)):\n",
    "        topics = lda.get_document_topics(bow=docs[d])\n",
    "        topics = sorted(topics,key=lambda k:k[1], reverse=True)\n",
    "        file.write(yearOfAbstract[d]+\":\\t\")\n",
    "        for t in topics[0:4]:\n",
    "            for word in [dictionary[x[0]] for x in lda.get_topic_terms(t[0],topn=3)]:\n",
    "                file.write(word+\"\\t\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = [(1,1),(2,2),(3,3),(3,3)]\n",
    "access = lambda x: x[1]\n",
    "algos.BinarySearch(alist,term=3,start=0,stop=len(alist)-1,accessElement=access)\n",
    "#alist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyAbstract(title='Pharmacogenomic Biomarkers for Improved Drug Therapy\\xe2\\x80\\x94Recent Progress and Future Developments', date=datetime.datetime(2018, 1, 1, 0, 0), text=u'much interindividual variability efficacy adverse reactions due polymorphisms genes encoding proteins involved pharmacokinetics pharmacodynamics immunological responses pharmacogenetic identified multitude genedrug associations resulted genetically guided dosing decisions yield success rate pharmacological rapid technological developments genetic analyses reveal genetic variants importance action much previously thought true personalized prediction requires attention millions rare mutations review evolutionary background genetic polymorphisms drugmetabolizing enzymes provide examples current pharmacogenomic biomarkers give update germline somatic genome biomarkers clinical practice discuss current technology emphasis complex genetic loci review current initiatives validation pharmacogenomic biomarkers scenarios future taking rare genetic variants account true personalized genetically guided prescription conclude pharmacogenomic information patient stratification value tailor optimized regimens particularly oncology routine pharmacogenomic biomarkers clinical practice therapeutic areas currently sparse prospects future implementation scrutinized international consortia \\xa9 2017 authorsabacavir allopurinol amoxicillin plus clavulanic atorvastatin azathioprine biological marker capecitabine carbamazepine clopidogrel codeine diclofenac metabolizing enzyme efavirenz flucloxacillin fluorouracil irinotecan isoniazid lumiracoxib mercaptopurine metoclopramide nevirapine perhexiline phenytoin proton pump inhibitor simvastatin tegafur ticlopidine unindexed warfarin ximelagatran biological marker abcb1 gene acute lymphoblastic leukemia alk gene allele analgesic bone marrow suppression cardiotoxicity clinical practice cyp gene cyp28 gene cyp2a6 gene cyp2b6 gene cyp2c19 gene cyp2c8 gene cyp2c9 gene cyp2d6 gene cyp3a4 gene cyp3a5 gene cyp4f2 gene cyp6 gene cyp6bq23 gene cyp6cy3 gene cyp6g1 gene cyp9q1 gene cyp9q2 gene cyp9q3 gene diarrhea dpyd gene dress syndrome efficacy information safety tolerability dystonia egfr gene erbb2 gene european medicines agency fgfr gene administration g6pd gene gene gene locus genetic variability genome genotype geographic distribution germline genome gstm1 gene heredity hla b gene hla gene homozygosity immunodeficiency virus infection hypersensitivity jak2 gene kit gene loss function mutation myopathy neurologic neurotoxicity neutropenia next generation sequencing oncogene oncology pdgfra gene personalized medicine pharmacodynamics pharmacogenetic variant pharmacogenomics prescription public review rhabdomyolysis slc19a1 gene slc22a1 gene slco1b1 gene somatic genome somatic mutation stevens johnson syndrome thrombocytopenia thromboembolism toxic epidermal necrolysis toxic hepatitis tpmt gene indication ugt1a1 gene ugt2b15 gene ugt2b17 gene vkorc1 gene genetic polymorphism genetic variation neoplasm patient satisfaction pharmacogenetics biomarkers genetic variation humans neoplasms oncogenes patient satisfaction pharmacogenetics polymorphism genetic precision medicine')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[len(abstracts)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
