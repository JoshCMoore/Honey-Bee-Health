{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import namedtuple\n",
    "import gensim.parsing.preprocessing as processing\n",
    "#Number of topics the model should index\n",
    "numberOfTopics = 125\n",
    "#Number of passes the model should make\n",
    "passes = 10\n",
    "MyAbstract = namedtuple('MyAbstract',[\"title\",\"date\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = open(\"../data/paperTable.tsv\",\"r\")\n",
    "entries = []\n",
    "for line in table:\n",
    "    entries.append(line.split('\\t'))\n",
    "table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\python2\\lib\\site-packages\\gensim\\parsing\\preprocessing.py:105: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  return \" \".join(w for w in s.split() if w not in STOPWORDS)\n"
     ]
    }
   ],
   "source": [
    "# Create a set of frequent words\n",
    "stopFile = open(\"../data/stopwords.txt\",\"r\")\n",
    "stopWords = stopFile.read().splitlines()\n",
    "stopWords.append(\"\\xc2\\xa9\") #This is the copyright symbol, this shows up in every abstract and should not be apart of the corpus\n",
    "stopWords.extend([\"\\u2019\",\"\\u03bc\",\"bee\",\"bees\",\"honey\",\"honeybee\",\"honeybees\"])\n",
    "stopList = set(stopWords)\n",
    "with open(\"../data/extraStopWords.txt\",\"r\") as extraStopFile:\n",
    "    stopWords.extend(extraStopFile.read().split(\"\\n\"))\n",
    "# Lowercase each document, split it by white space and filter out stopWords\n",
    "processing.STOPWORDS = stopWords\n",
    "def removeStops(text):\n",
    "    return processing.remove_stopwords(text.lower().translate(None, string.punctuation))\n",
    "# List of lists in \n",
    "abstracts = [MyAbstract._make([art[0],datetime.strptime(art[4][:-1], '%Y-%m-%d'),removeStops((art[1]+art[2]+art[3]))]) for art in entries]\n",
    "abstracts.sort(key=lambda q: q.date.year)\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for abst in abstracts:\n",
    "    for token in abst[2].split(\" \"):\n",
    "        frequency[token] += 1\n",
    "processedCorpus = [[token for token in abst[2].split(\" \") if frequency[token] > 5] for abst in abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary of tokens\n",
    "tempFolder = tempfile.gettempdir()\n",
    "dictionary = corpora.Dictionary(processedCorpus)\n",
    "dictionary.save(os.path.join(tempFolder,'words.dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create general corpus and serialize in order for it to be iterated over\n",
    "corpus = [dictionary.doc2bow(text) for text in processedCorpus]\n",
    "corpora.MmCorpus.serialize(os.path.join(tempFolder, 'words.dict'), corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above corpus shows the amount of times every word used in the documents is used in every indevidual document. Every word is represented by a token ID, the list of which can be found in \"words.dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-04 19:42:34,569 : INFO : using symmetric alpha at 0.008\n",
      "2018-06-04 19:42:34,572 : INFO : using symmetric eta at 0.008\n",
      "2018-06-04 19:42:34,575 : INFO : using serial LDA version on this node\n",
      "2018-06-04 19:42:34,683 : INFO : running online (multi-pass) LDA training, 125 topics, 10 passes over the supplied corpus of 1044 documents, updating model once every 1044 documents, evaluating perplexity every 1044 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-06-04 19:42:37,869 : INFO : -22.686 per-word bound, 6749128.9 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:42:37,872 : INFO : PROGRESS: pass 0, at document #1044/1044\n",
      "2018-06-04 19:42:40,542 : INFO : topic #80 (0.008): 0.015*\"colony\" + 0.014*\"pesticide\" + 0.010*\"imidacloprid\" + 0.009*\"thiamethoxam\" + 0.007*\"insecticide\" + 0.007*\"larval\" + 0.007*\"insecticides\" + 0.006*\"larvae\" + 0.006*\"concentration\" + 0.005*\"sonication\"\n",
      "2018-06-04 19:42:40,543 : INFO : topic #2 (0.008): 0.019*\"pollen\" + 0.011*\"toxicity\" + 0.010*\"colony\" + 0.007*\"imidacloprid\" + 0.007*\"thiamethoxam\" + 0.007*\"insecticides\" + 0.007*\"neonicotinoid\" + 0.006*\"©\" + 0.006*\"nectar\" + 0.006*\"native\"\n",
      "2018-06-04 19:42:40,546 : INFO : topic #110 (0.008): 0.018*\"pesticide\" + 0.010*\"virus\" + 0.007*\"colony\" + 0.006*\"mixtures\" + 0.006*\"neonicotinoids\" + 0.006*\"service\" + 0.006*\"us\" + 0.006*\"©\" + 0.006*\"performance\" + 0.006*\"neonicotinoid\"\n",
      "2018-06-04 19:42:40,549 : INFO : topic #60 (0.008): 0.021*\"pollinators\" + 0.012*\"©\" + 0.008*\"colony\" + 0.008*\"impact\" + 0.007*\"pollen\" + 0.006*\"approach\" + 0.006*\"compared\" + 0.006*\"cycle\" + 0.006*\"varroa\" + 0.006*\"biology\"\n",
      "2018-06-04 19:42:40,552 : INFO : topic #73 (0.008): 0.012*\"varroa\" + 0.010*\"mite\" + 0.009*\"pollen\" + 0.008*\"©\" + 0.008*\"nosema\" + 0.007*\"destructor\" + 0.007*\"parasites\" + 0.006*\"interaction\" + 0.006*\"acari\" + 0.006*\"ceranae\"\n",
      "2018-06-04 19:42:40,556 : INFO : topic diff=75.753151, rho=1.000000\n",
      "2018-06-04 19:42:42,766 : INFO : -11.130 per-word bound, 2241.6 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:42:42,769 : INFO : PROGRESS: pass 1, at document #1044/1044\n",
      "C:\\tools\\Anaconda3\\envs\\python2\\lib\\site-packages\\gensim\\models\\ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "2018-06-04 19:42:44,332 : INFO : topic #61 (0.008): 0.023*\"colony\" + 0.017*\"virus\" + 0.016*\"nosema\" + 0.013*\"ccd\" + 0.013*\"mortality\" + 0.009*\"ceranae\" + 0.008*\"pathogen\" + 0.008*\"collapse\" + 0.007*\"pollen\" + 0.007*\"states\"\n",
      "2018-06-04 19:42:44,335 : INFO : topic #57 (0.008): 0.017*\"stress\" + 0.014*\"hives\" + 0.011*\"cylinders\" + 0.011*\"colony\" + 0.010*\"model\" + 0.009*\"hive\" + 0.009*\"collapse\" + 0.009*\"virus\" + 0.008*\"lower\" + 0.007*\"queen\"\n",
      "2018-06-04 19:42:44,339 : INFO : topic #30 (0.008): 0.013*\"pollen\" + 0.013*\"colony\" + 0.011*\"pesticide\" + 0.009*\"©\" + 0.007*\"virus\" + 0.007*\"cells\" + 0.007*\"brood\" + 0.006*\"thiamethoxam\" + 0.006*\"varroa\" + 0.006*\"neonicotinoids\"\n",
      "2018-06-04 19:42:44,342 : INFO : topic #58 (0.008): 0.012*\"forage\" + 0.011*\"colony\" + 0.010*\"pollen\" + 0.008*\"semen\" + 0.007*\"brood\" + 0.007*\"policy\" + 0.007*\"conservation\" + 0.007*\"pesticide\" + 0.006*\"fresh\" + 0.006*\"varroa\"\n",
      "2018-06-04 19:42:44,345 : INFO : topic #21 (0.008): 0.023*\"kunkeei\" + 0.017*\"bacterial\" + 0.014*\"genome\" + 0.014*\"body\" + 0.014*\"lactobacillus\" + 0.013*\"mp2\" + 0.012*\"nicotine\" + 0.012*\"gene\" + 0.011*\"larvae\" + 0.010*\"genetic\"\n",
      "2018-06-04 19:42:44,351 : INFO : topic diff=inf, rho=0.577350\n",
      "2018-06-04 19:42:46,444 : INFO : -10.181 per-word bound, 1161.2 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:42:46,446 : INFO : PROGRESS: pass 2, at document #1044/1044\n",
      "2018-06-04 19:42:47,779 : INFO : topic #18 (0.008): 0.022*\"mites\" + 0.016*\"varroa\" + 0.008*\"reproduction\" + 0.008*\"©\" + 0.008*\"male\" + 0.007*\"flight\" + 0.007*\"insecticide\" + 0.007*\"brood\" + 0.007*\"neonicotinoid\" + 0.007*\"sealed\"\n",
      "2018-06-04 19:42:47,782 : INFO : topic #81 (0.008): 0.015*\"ccd\" + 0.014*\"million\" + 0.013*\"many\" + 0.013*\"extension\" + 0.013*\"nutrition\" + 0.012*\"federal\" + 0.012*\"next\" + 0.011*\"restricted\" + 0.011*\"plan\" + 0.010*\"mite\"\n",
      "2018-06-04 19:42:47,785 : INFO : topic #32 (0.008): 0.011*\"dna\" + 0.011*\"virus\" + 0.008*\"colony\" + 0.007*\"pollen\" + 0.007*\"©\" + 0.006*\"sequence\" + 0.006*\"genome\" + 0.006*\"methods\" + 0.006*\"gene\" + 0.006*\"destructor\"\n",
      "2018-06-04 19:42:47,786 : INFO : topic #78 (0.008): 0.012*\"concentration\" + 0.011*\"gene\" + 0.011*\"fungicide\" + 0.010*\"colony\" + 0.009*\"pollen\" + 0.008*\"lindane\" + 0.008*\"mixture\" + 0.007*\"ops\" + 0.007*\"©\" + 0.007*\"tested\"\n",
      "2018-06-04 19:42:47,789 : INFO : topic #52 (0.008): 0.015*\"mirnas\" + 0.009*\"sequencing\" + 0.009*\"gut\" + 0.008*\"transcriptome\" + 0.008*\"vsh\" + 0.008*\"routing\" + 0.008*\"immune\" + 0.007*\"viruses\" + 0.007*\"perrara\" + 0.007*\"networks\"\n",
      "2018-06-04 19:42:47,792 : INFO : topic diff=inf, rho=0.500000\n",
      "2018-06-04 19:42:49,665 : INFO : -9.585 per-word bound, 767.9 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:42:49,667 : INFO : PROGRESS: pass 3, at document #1044/1044\n",
      "2018-06-04 19:42:51,023 : INFO : topic #74 (0.008): 0.016*\"propolis\" + 0.016*\"resins\" + 0.014*\"mite\" + 0.011*\"bud\" + 0.008*\"grooming\" + 0.008*\"antimicrobial\" + 0.008*\"composition\" + 0.007*\"rate\" + 0.007*\"european\" + 0.007*\"pollution\"\n",
      "2018-06-04 19:42:51,026 : INFO : topic #11 (0.008): 0.022*\"larvae\" + 0.011*\"death\" + 0.010*\"resistance\" + 0.009*\"diseases\" + 0.008*\"mortality\" + 0.007*\"©\" + 0.007*\"apiaries\" + 0.007*\"s\" + 0.007*\"according\" + 0.007*\"midgut\"\n",
      "2018-06-04 19:42:51,029 : INFO : topic #124 (0.008): 0.019*\"nosema\" + 0.017*\"social\" + 0.015*\"destructor\" + 0.012*\"colony\" + 0.010*\"mite\" + 0.010*\"varroa\" + 0.009*\"argentina\" + 0.008*\"ceranae\" + 0.008*\"parasitized\" + 0.007*\"©\"\n",
      "2018-06-04 19:42:51,030 : INFO : topic #28 (0.008): 0.023*\"varroa\" + 0.015*\"destructor\" + 0.012*\"colony\" + 0.011*\"virus\" + 0.009*\"pesticide\" + 0.008*\"mites\" + 0.008*\"©\" + 0.007*\"mite\" + 0.006*\"immune\" + 0.006*\"residues\"\n",
      "2018-06-04 19:42:51,032 : INFO : topic #6 (0.008): 0.032*\"pollen\" + 0.021*\"protein\" + 0.019*\"gene\" + 0.010*\"rj\" + 0.010*\"nutritional\" + 0.010*\"nutrition\" + 0.010*\"fed\" + 0.009*\"pollens\" + 0.009*\"vitellogenin\" + 0.008*\"physiology\"\n",
      "2018-06-04 19:42:51,038 : INFO : topic diff=inf, rho=0.447214\n",
      "2018-06-04 19:42:53,147 : INFO : -9.170 per-word bound, 575.9 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:42:53,150 : INFO : PROGRESS: pass 4, at document #1044/1044\n",
      "2018-06-04 19:42:54,618 : INFO : topic #47 (0.008): 0.019*\"insecticides\" + 0.017*\"neonicotinoid\" + 0.014*\"pollen\" + 0.011*\"soil\" + 0.011*\"residues\" + 0.010*\"faustovirus\" + 0.010*\"seed\" + 0.009*\"fields\" + 0.009*\"residue\" + 0.008*\"pollutant\"\n",
      "2018-06-04 19:42:54,624 : INFO : topic #99 (0.008): 0.029*\"heart\" + 0.017*\"viruses\" + 0.017*\"rna\" + 0.016*\"virus\" + 0.014*\"octopamine\" + 0.010*\"reaction\" + 0.009*\"10\" + 0.009*\"genes\" + 0.008*\"polymerase\" + 0.008*\"deformed\"\n",
      "2018-06-04 19:42:54,627 : INFO : topic #75 (0.008): 0.027*\"pollen\" + 0.019*\"seed\" + 0.018*\"pesticide\" + 0.018*\"pest\" + 0.009*\"value\" + 0.008*\"rsd\" + 0.007*\"©\" + 0.007*\"stored\" + 0.007*\"farmers\" + 0.006*\"g−1\"\n",
      "2018-06-04 19:42:54,630 : INFO : topic #35 (0.008): 0.052*\"pollen\" + 0.016*\"colony\" + 0.016*\"foraging\" + 0.010*\"nectar\" + 0.009*\"pollinator\" + 0.008*\"©\" + 0.007*\"pollinators\" + 0.007*\"landscape\" + 0.007*\"pesticide\" + 0.006*\"quality\"\n",
      "2018-06-04 19:42:54,631 : INFO : topic #101 (0.008): 0.037*\"pollen\" + 0.028*\"hazard\" + 0.017*\"ld50\" + 0.012*\"quotients\" + 0.012*\"latin\" + 0.012*\"pesticide\" + 0.010*\"america\" + 0.009*\"ranged\" + 0.008*\"per\" + 0.008*\"pollution\"\n",
      "2018-06-04 19:42:54,635 : INFO : topic diff=inf, rho=0.408248\n",
      "2018-06-04 19:42:56,719 : INFO : -8.875 per-word bound, 469.4 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:42:56,720 : INFO : PROGRESS: pass 5, at document #1044/1044\n",
      "2018-06-04 19:42:58,342 : INFO : topic #97 (0.008): 0.054*\"genetic\" + 0.026*\"sequence\" + 0.024*\"polymorphism\" + 0.023*\"recombination\" + 0.022*\"ceranae\" + 0.020*\"nosema\" + 0.016*\"dna\" + 0.016*\"single\" + 0.013*\"nucleotide\" + 0.013*\"fungal\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-04 19:42:58,345 : INFO : topic #41 (0.008): 0.012*\"range\" + 0.012*\"mg\" + 0.011*\"validation\" + 0.010*\"limits\" + 0.010*\"al\" + 0.010*\"future\" + 0.010*\"©\" + 0.010*\"001\" + 0.010*\"et\" + 0.009*\"residue\"\n",
      "2018-06-04 19:42:58,346 : INFO : topic #73 (0.008): 0.033*\"varroa\" + 0.020*\"mite\" + 0.018*\"destructor\" + 0.016*\"acari\" + 0.014*\"interaction\" + 0.013*\"apidae\" + 0.013*\"parasites\" + 0.012*\"newfoundland\" + 0.011*\"hostparasite\" + 0.010*\"canada\"\n",
      "2018-06-04 19:42:58,351 : INFO : topic #18 (0.008): 0.024*\"mites\" + 0.017*\"varroa\" + 0.010*\"reproduction\" + 0.010*\"male\" + 0.009*\"flight\" + 0.008*\"brood\" + 0.008*\"sealed\" + 0.008*\"©\" + 0.007*\"mitochondria\" + 0.007*\"insecticide\"\n",
      "2018-06-04 19:42:58,352 : INFO : topic #1 (0.008): 0.017*\"nicotine\" + 0.011*\"neonicotinoid\" + 0.010*\"colony\" + 0.009*\"queens\" + 0.009*\"pesticide\" + 0.008*\"male\" + 0.008*\"coli\" + 0.007*\"thiamethoxam\" + 0.007*\"©\" + 0.007*\"genetic\"\n",
      "2018-06-04 19:42:58,357 : INFO : topic diff=inf, rho=0.377964\n",
      "2018-06-04 19:43:00,611 : INFO : -8.663 per-word bound, 405.4 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:43:00,614 : INFO : PROGRESS: pass 6, at document #1044/1044\n",
      "2018-06-04 19:43:02,349 : INFO : topic #96 (0.008): 0.028*\"pollen\" + 0.011*\"fipronil\" + 0.010*\"pollinator\" + 0.009*\"males\" + 0.009*\"transsylvanica\" + 0.008*\"nontarget\" + 0.008*\"destructor\" + 0.008*\"cuphea\" + 0.008*\"oilseed\" + 0.008*\"nectar\"\n",
      "2018-06-04 19:43:02,351 : INFO : topic #114 (0.008): 0.022*\"imidacloprid\" + 0.014*\"gene\" + 0.011*\"insecticide\" + 0.010*\"insecticides\" + 0.010*\"fipronil\" + 0.009*\"genes\" + 0.008*\"feeding\" + 0.007*\"dehydrogenase\" + 0.007*\"physiological\" + 0.007*\"nitro\"\n",
      "2018-06-04 19:43:02,355 : INFO : topic #28 (0.008): 0.024*\"varroa\" + 0.016*\"destructor\" + 0.010*\"colony\" + 0.009*\"©\" + 0.008*\"virus\" + 0.007*\"mites\" + 0.007*\"mite\" + 0.007*\"immune\" + 0.007*\"resistance\" + 0.007*\"proteins\"\n",
      "2018-06-04 19:43:02,357 : INFO : topic #15 (0.008): 0.014*\"pesticide\" + 0.013*\"pollen\" + 0.012*\"chlorpyrifos\" + 0.009*\"©\" + 0.009*\"varroa\" + 0.008*\"hive\" + 0.008*\"gas\" + 0.007*\"insecticide\" + 0.007*\"agriculture\" + 0.007*\"antimicrobial\"\n",
      "2018-06-04 19:43:02,358 : INFO : topic #26 (0.008): 0.025*\"unigenes\" + 0.018*\"cerana\" + 0.012*\"oil\" + 0.012*\"c\" + 0.012*\"larvae\" + 0.010*\"oregano\" + 0.010*\"nontreated\" + 0.010*\"transcriptome\" + 0.010*\"4\" + 0.010*\"controls\"\n",
      "2018-06-04 19:43:02,364 : INFO : topic diff=inf, rho=0.353553\n",
      "2018-06-04 19:43:04,785 : INFO : -8.511 per-word bound, 364.9 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:43:04,786 : INFO : PROGRESS: pass 7, at document #1044/1044\n",
      "2018-06-04 19:43:06,670 : INFO : topic #18 (0.008): 0.025*\"mites\" + 0.018*\"varroa\" + 0.011*\"reproduction\" + 0.010*\"male\" + 0.009*\"flight\" + 0.009*\"brood\" + 0.009*\"sealed\" + 0.008*\"©\" + 0.008*\"mitochondria\" + 0.007*\"destructor\"\n",
      "2018-06-04 19:43:06,671 : INFO : topic #76 (0.008): 0.038*\"pesticide\" + 0.022*\"tandem\" + 0.019*\"gas\" + 0.017*\"residues\" + 0.016*\"phase\" + 0.015*\"limit\" + 0.014*\"ngg\" + 0.013*\"solid\" + 0.013*\"quechers\" + 0.013*\"residue\"\n",
      "2018-06-04 19:43:06,674 : INFO : topic #111 (0.008): 0.023*\"rna\" + 0.012*\"enzyme\" + 0.011*\"virus\" + 0.010*\"regions\" + 0.010*\"region\" + 0.009*\"protein\" + 0.008*\"transcription\" + 0.008*\"flumethrin\" + 0.008*\"mexico\" + 0.008*\"stress\"\n",
      "2018-06-04 19:43:06,677 : INFO : topic #37 (0.008): 0.012*\"pesticide\" + 0.011*\"thiacloprid\" + 0.011*\"varroa\" + 0.009*\"colony\" + 0.008*\"©\" + 0.008*\"monitoring\" + 0.008*\"dynamics\" + 0.007*\"analytical\" + 0.007*\"viruses\" + 0.006*\"propolis\"\n",
      "2018-06-04 19:43:06,681 : INFO : topic #29 (0.008): 0.026*\"larvae\" + 0.021*\"varroa\" + 0.018*\"gene\" + 0.018*\"acaricides\" + 0.017*\"coumaphos\" + 0.016*\"larva\" + 0.014*\"mite\" + 0.013*\"treated\" + 0.013*\"rearing\" + 0.012*\"queen\"\n",
      "2018-06-04 19:43:06,687 : INFO : topic diff=inf, rho=0.333333\n",
      "2018-06-04 19:43:09,170 : INFO : -8.402 per-word bound, 338.3 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:43:09,171 : INFO : PROGRESS: pass 8, at document #1044/1044\n",
      "2018-06-04 19:43:11,163 : INFO : topic #67 (0.008): 0.013*\"concentration\" + 0.011*\"gis\" + 0.011*\"μg\" + 0.011*\"5\" + 0.010*\"kg−1\" + 0.010*\"contamination\" + 0.009*\"pesticide\" + 0.009*\"©\" + 0.009*\"impact\" + 0.008*\"velutina\"\n",
      "2018-06-04 19:43:11,164 : INFO : topic #65 (0.008): 0.040*\"pollen\" + 0.019*\"lipid\" + 0.018*\"protein\" + 0.013*\"bumble\" + 0.012*\"pl\" + 0.011*\"nutritional\" + 0.010*\"intake\" + 0.008*\"diets\" + 0.008*\"fungicides\" + 0.008*\"larvae\"\n",
      "2018-06-04 19:43:11,167 : INFO : topic #74 (0.008): 0.017*\"propolis\" + 0.017*\"resins\" + 0.015*\"mite\" + 0.012*\"bud\" + 0.010*\"antimicrobial\" + 0.009*\"grooming\" + 0.008*\"composition\" + 0.008*\"rate\" + 0.008*\"european\" + 0.007*\"pollution\"\n",
      "2018-06-04 19:43:11,171 : INFO : topic #62 (0.008): 0.067*\"propolis\" + 0.025*\"immune\" + 0.023*\"antimicrobial\" + 0.018*\"protein\" + 0.017*\"virus\" + 0.017*\"colony\" + 0.015*\"social\" + 0.014*\"immunity\" + 0.013*\"activities\" + 0.012*\"envelope\"\n",
      "2018-06-04 19:43:11,174 : INFO : topic #104 (0.008): 0.012*\"cerana\" + 0.012*\"biosecurity\" + 0.012*\"fatty\" + 0.011*\"toxicity\" + 0.010*\"stress\" + 0.010*\"©\" + 0.009*\"omega3\" + 0.009*\"lc5024h\" + 0.009*\"mixture\" + 0.008*\"ppm\"\n",
      "2018-06-04 19:43:11,177 : INFO : topic diff=inf, rho=0.316228\n",
      "2018-06-04 19:43:13,759 : INFO : -8.322 per-word bound, 320.1 perplexity estimate based on a held-out corpus of 1044 documents with 116344 words\n",
      "2018-06-04 19:43:13,760 : INFO : PROGRESS: pass 9, at document #1044/1044\n",
      "2018-06-04 19:43:15,802 : INFO : topic #62 (0.008): 0.070*\"propolis\" + 0.025*\"immune\" + 0.024*\"antimicrobial\" + 0.018*\"protein\" + 0.017*\"virus\" + 0.017*\"colony\" + 0.016*\"social\" + 0.014*\"immunity\" + 0.013*\"activities\" + 0.012*\"envelope\"\n",
      "2018-06-04 19:43:15,805 : INFO : topic #100 (0.008): 0.014*\"pesticide\" + 0.011*\"±\" + 0.010*\"body\" + 0.009*\"pest\" + 0.009*\"mg100\" + 0.009*\"mg\" + 0.009*\"major\" + 0.008*\"©\" + 0.007*\"hives\" + 0.007*\"incidents\"\n",
      "2018-06-04 19:43:15,809 : INFO : topic #44 (0.008): 0.051*\"iapv\" + 0.038*\"virus\" + 0.029*\"genome\" + 0.021*\"genetic\" + 0.019*\"capsid\" + 0.019*\"proteins\" + 0.018*\"dicistroviridae\" + 0.017*\"protein\" + 0.014*\"colony\" + 0.012*\"acute\"\n",
      "2018-06-04 19:43:15,812 : INFO : topic #1 (0.008): 0.018*\"nicotine\" + 0.013*\"neonicotinoid\" + 0.010*\"colony\" + 0.010*\"queens\" + 0.010*\"pesticide\" + 0.008*\"coli\" + 0.008*\"thiamethoxam\" + 0.008*\"male\" + 0.008*\"males\" + 0.007*\"©\"\n",
      "2018-06-04 19:43:15,813 : INFO : topic #113 (0.008): 0.019*\"indigenous\" + 0.018*\"stingless\" + 0.015*\"toxicity\" + 0.015*\"fungicides\" + 0.015*\"pollen\" + 0.013*\"knowledge\" + 0.012*\"©\" + 0.012*\"residues\" + 0.011*\"academic\" + 0.011*\"native\"\n",
      "2018-06-04 19:43:15,819 : INFO : topic diff=inf, rho=0.301511\n"
     ]
    }
   ],
   "source": [
    "# Train the model and set number of topics\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "lda = models.ldamodel.LdaModel(corpus,id2word=dictionary,num_topics=numberOfTopics,passes=passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the most interesting words per topic per document\n",
    "# This cell does not need to be run if only trying to create Top Nine terms per paper\n",
    "topicOrganizingFile = open(\"../data/topicorganization.tsv\",\"w\")\n",
    "for x in xrange(0,len(abstracts)):\n",
    "    doc = dictionary.doc2bow(abstracts[x].split())\n",
    "    docTopics, wordTopics, phiValues = lda.get_document_topics(doc, per_word_topics=True)\n",
    "    topicOrganizingFile.write(yearOfAbstract[x]+\"\\t\"+titleOfAbstract[x]+\"\\t\")\n",
    "    for y in xrange(0,min(3,len(docTopics))):\n",
    "        topicnumber = docTopics[y][0]\n",
    "        topicOrganizingFile.write(str(lda.show_topic(topicnumber))+\"\\t\")\n",
    "        #Sorts the word topics in decending order based on their greatest phi value\n",
    "        for z in xrange(0,len(phiValues)):\n",
    "            phiValues[z][1].sort(key=lambda q:q[1],reverse=True)\n",
    "        phiValues.sort(key=lambda q:q[1][0][1],reverse=True)\n",
    "        curindex=0\n",
    "        topwords = \"\"\n",
    "        for z in xrange(0,3):\n",
    "            while curindex<len(phiValues) and phiValues[curindex][1][0][0]!=topicnumber:\n",
    "                curindex+=1\n",
    "            if(curindex>=len(phiValues)):break\n",
    "            print len(phiValues)\n",
    "            print dictionary[phiValues[curindex][0]]\n",
    "            topwords+=str(dictionary[phiValues[curindex][0]].encode('utf-8').strip())+\" \"\n",
    "            curindex+=1\n",
    "        filter(lambda a:a[0]!=topicnumber,phiValues)\n",
    "        topicOrganizingFile.write(topwords+\"\\t\")\n",
    "    topicOrganizingFile.write(\"\\n\")\n",
    "topicOrganizingFile.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicWords = []\n",
    "for i in range(0,numberOfTopics):\n",
    "    t = lda.get_topic_terms(i,50)\n",
    "    currentWordList = []\n",
    "    for x in t:\n",
    "        word = str(dictionary[x[0]])\n",
    "        if word not in currentWordList:\n",
    "            currentWordList.append(word)\n",
    "    topicWords.append(currentWordList)\n",
    "topicListFile = open(\"../data/TopicWords/List-\"+str(numberOfTopics)+\".txt\",\"w+\")\n",
    "for i in range(0,len(topicWords)):\n",
    "    topicListFile.write(\"Topic \"+str(i)+\":\\n\")\n",
    "    for j in topicWords[i]:\n",
    "        topicListFile.write(j+'\\n')\n",
    "    topicListFile.write('\\n')\n",
    "topicListFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes the top nine terms for each document\n",
    "\n",
    "topNineFile = open(\"../data/Docbow/TopNineTerms-\"+str(numberOfTopics)+\".tsv\",\"w\")\n",
    "for abstr in abstracts:\n",
    "    doc = dictionary.doc2bow(abstracts[2].split()) # Convert to bag of words format first\n",
    "    # Get the topics and words associated with each document\n",
    "    docTopics, wordTopics, phiValues = lda.get_document_topics(doc, per_word_topics=True)\n",
    "    topNineFile.write(yearOfAbstract[x]+\"\\t\"+abst+\"\\t\")\n",
    "    for z in xrange(0,len(phiValues)):\n",
    "        phiValues[z][1].sort(key=lambda q:q[1],reverse=True)\n",
    "    phiValues.sort(key=lambda q:q[1][0][1],reverse=True)\n",
    "    nineWords = \"\"\n",
    "    for x in phiValues[:15]:\n",
    "        nineWords+= dictionary[x[0]] + \" \"\n",
    "    topNineFile.write(nineWords.encode('utf-8')+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the top 5 topics and top 3 words per topic\n",
    "with open(\"../data/Docbow/Top5TopicsTop3WordsTop=\"+str(numberOfTopics)+\".tsv\",\"w\") as file:\n",
    "    docs = [dictionary.doc2bow(a.split()) for a in abstracts] # Convert to bag of words format first\n",
    "    for d in xrange(0,len(docs)):\n",
    "        topics = lda.get_document_topics(bow=docs[d])\n",
    "        topics = sorted(topics,key=lambda k:k[1], reverse=True)\n",
    "        file.write(yearOfAbstract[d]+\":\\t\")\n",
    "        for t in topics[0:4]:\n",
    "            for word in [dictionary[x[0]] for x in lda.get_topic_terms(t[0],topn=3)]:\n",
    "                file.write(word+\"\\t\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyAbstract(title='World bee health update 1996', date=datetime.datetime(1996, 1, 1, 0, 0), text=u'comprehensive review world published world 199310 updated 199511 supplement correct records given earlier brief update includes new reports records included previous articles series make useful incorporates records published 1995 update read original review reference status almost every country worldapis')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
