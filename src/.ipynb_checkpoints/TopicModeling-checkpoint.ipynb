{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import logging\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from datetime import datetime\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import namedtuple\n",
    "import gensim.parsing.preprocessing as processing\n",
    "from os import listdir\n",
    "import CustomApi as api\n",
    "#Start Global Variables and Types\n",
    "\n",
    "#document dir\n",
    "docs = \"../data/documents/\"\n",
    "\n",
    "#Number of topics the model should index\n",
    "numberOfTopics = 225\n",
    "\n",
    "#Number of passes the model should make\n",
    "passes = 75\n",
    "\n",
    "#Keyphrase tracker\n",
    "keyphraseTracker = api.KeyWordTracker()\n",
    "\n",
    "#End Global Variables and Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(docs+\"lt2006/\")\n",
    "entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with open(docs+\"lt2006/\"+file,\"rb\") as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            if \"Authors\" not in row[0] and row[15] !='[No abstract available]':\n",
    "                entries.append(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Evidence of the Juvenile Hormone Methyl(2E,6E)-10,11-epoxy-3,7,11-trimethyl-2,6-dodecadienoate(JH-3) in Insects of Four Orders'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title of an abstract\n",
    "entries[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of frequent words\n",
    "stopFile = open(\"../data/stopwords.txt\",\"r\")\n",
    "stopWords = stopFile.read().splitlines() #This is the copyright symbol, this shows up in every abstract and should not be apart of the corpus\n",
    "stopWords.extend([u\"\\u2019\",u\"\\u03bc\",\"bee\",\"bees\",\"honey\",\"honeybee\",\"honeybees\",u\"\\xa9\",u\"\\xc2\"])\n",
    "# for asc in range(97,123):\n",
    "#     stopWords.extend([chr(asc)])\n",
    "with open(\"../data/extraStopWords.txt\",\"r\") as extraStopFile:\n",
    "    stopWords.extend(extraStopFile.read().split(\"\\n\"))\n",
    "# Lowercase each document, split it by white space and filter out stopWords\n",
    "stopList = set(stopWords)\n",
    "processing.STOPWORDS = stopList\n",
    "ps = PorterStemmer()\n",
    "def removeStops(text):\n",
    "    stopsRemoved = processing.remove_stopwords(text.lower().translate(None, string.punctuation))\n",
    "    words = stopsRemoved.split(\" \")\n",
    "    stemmedWords = []\n",
    "    for w in words:\n",
    "        if len(ps.stem(w)) > 2:\n",
    "            stemmedWords.append(ps.stem(w))\n",
    "    return ' '.join(stemmedWords)\n",
    "# Each abstract has a 'title':String, 'date':datetime.datetime, 'text':String, and 'keywords':String\n",
    "abstracts = [api.MyAbstract._make([art[1],datetime.strptime(art[2], '%Y'),removeStops(art[15]), art[16]]) for art in entries]\n",
    "abstracts.sort(key=lambda q: q.date.year)\n",
    "entries = None\n",
    "# Count word frequencies\n",
    "selections = []\n",
    "\n",
    "access = lambda x: x.date.year\n",
    "lastIndex = 0\n",
    "for i in range(1957,2007):\n",
    "    index = api.binarySearch(abstracts,i,access)\n",
    "    if  index != -1:\n",
    "        selections.append(abstracts[lastIndex:index+1])\n",
    "        lastIndex = index+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def createCorpus(selection):\n",
    "    frequency = defaultdict(int)\n",
    "    for abst in abstracts:\n",
    "        for token in abst.text.split(\" \"):\n",
    "            frequency[token] += 1\n",
    "    tempFolder = tempfile.gettempdir()\n",
    "    processedCorpus = [[token for token in abst.text.split(\" \") if frequency[token] > 5] for abst in selection]\n",
    "    dictionary = corpora.Dictionary(processedCorpus)\n",
    "    dictionary.save(os.path.join(tempFolder,'words.dict'))\n",
    "    # Create general corpus and serialize in order for it to be iterated over\n",
    "    corpus = [dictionary.doc2bow(text) for text in processedCorpus]\n",
    "    corpora.MmCorpus.serialize(os.path.join(tempFolder, 'words.dict'), corpus)\n",
    "    return api.MyCorpora._make([corpus,dictionary])\n",
    "    \n",
    "\n",
    "\n",
    "# Save the dictionary of tokens\n",
    "# def createModel():\n",
    "#     tempFolder = tempfile.gettempdir()\n",
    "#     dictionary = corpora.Dictionary(processedCorpusFor(selection))\n",
    "#     dictionary.save(os.path.join(tempFolder,'words.dict'))\n",
    "#     # Create general corpus and serialize in order for it to be iterated over\n",
    "#     corpus = [dictionary.doc2bow(text) for text in processedCorpus]\n",
    "#     corpora.MmCorpus.serialize(os.path.join(tempFolder, 'words.dict'), corpus)\n",
    "    # Train the model and set number of topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTopicsExport = 50\n",
    "\n",
    "def exportResults(path, sortedVals,wordDict):\n",
    "    seg = sortedVals[0][0:numTopicsExport]\n",
    "    #Edges and their weights [(a,b):weight]\n",
    "    edges = sortedVals[1]\n",
    "    # set of (a,b)\n",
    "    exportEdges = set({})\n",
    "    exportNodes = set({})\n",
    "    for node in seg:\n",
    "        exportNodes.add((node[\"tag\"],node[\"word\"],node[\"occurences\"]))\n",
    "        for e in node[\"edges\"]:\n",
    "            a = wordDict[e[0]]\n",
    "            b = wordDict[e[1]]\n",
    "            if a in seg and b in seg:\n",
    "                exportEdges.add(e)\n",
    "                exportNodes.add((a[\"tag\"],a[\"word\"],a[\"occurences\"]))\n",
    "                exportNodes.add((b[\"tag\"],b[\"word\"],b[\"occurences\"]))\n",
    "            \n",
    "    with open(path+\"nodes.csv\",\"w\") as file:\n",
    "        file.write(\"Id,Label,Weight\\n\")\n",
    "        for val in exportNodes:\n",
    "            file.write(str(val[0])+\",\"+val[1].encode('utf8')+','+str(val[2])+'\\n')\n",
    "    with open(path+'edges.csv',\"w\") as file:\n",
    "        file.write(\"Source,Target,Weight\\n\")\n",
    "        #We dont want to have duplicate edges written, so we want to make an aedge buffer and then write the buffer\n",
    "        for e in exportEdges:\n",
    "            file.write(str(e[0])+\",\"+str(e[1])+\",\"+str(edges[e])+\"\\n\")\n",
    "#         edgesToWrite = set([])\n",
    "#         for val in seg:\n",
    "#             #Edges a node has\n",
    "#             for edge in val[\"edges\"]:\n",
    "#                 #Check if (a,b) is an edge else if (b,a) is an edge. The graph is undirected so we dont want duplicates\n",
    "#                 if edge in edges.keys():\n",
    "#                     #Edge wasnt in the buffer, add it\n",
    "#                     if edge not in edgesToWrite:\n",
    "#                         edgesToWrite.add(edge)\n",
    "#                 #(b,a) in edge list?\n",
    "#                 elif (edge[1],edge[0]) in edges.keys():\n",
    "#                     #edge wasnt in the buffer\n",
    "#                     edgesToWrite.add(edge)\n",
    "#         for edge in edgesToWrite:\n",
    "#             file.write(str(edge[0])+\",\"+str(edge[1])+\",\"+str(edges[edge])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "def getResults(topics):\n",
    "    mapper = api.WordMapper()\n",
    "    #Edges [(a,b):weight]\n",
    "    edges = {}\n",
    "    def updateEdgeFreq(vec1):\n",
    "        if vec1[0] == vec1[1]:\n",
    "            return None\n",
    "        altVec = [vec1[1],vec1[0]]\n",
    "        if vec1 in edges.keys():\n",
    "            edges[vec1] += 1\n",
    "            return vec1\n",
    "        elif altVec in edges.keys():\n",
    "            edges[altVec] += 1\n",
    "            return altVec\n",
    "        else:\n",
    "            edges[vec1] = 1\n",
    "            return vec1\n",
    "    occurences = {}\n",
    "    topics[len(topics)-1]\n",
    "    for topic in topics:\n",
    "        words = topic[0]\n",
    "        #make all the edges for this topic\n",
    "        wordEdges = []\n",
    "        wid = mapper.mapWord(words[0][1])\n",
    "        for t in words:\n",
    "            edge = updateEdgeFreq((wid,mapper.mapWord(t[1])))\n",
    "            if edge != None:\n",
    "                wordEdges.append(edge)\n",
    "        #add the edges to each word and and update the number of occurences per word\n",
    "        for w in words:\n",
    "            word = w[1]\n",
    "            wid = mapper.mapWord(word)\n",
    "            if wid not in occurences.keys():\n",
    "                occurences[wid] = {\"prob\":w[0],\"occurences\":1,\"edges\":wordEdges, \"tag\" : wid, \"word\":word}\n",
    "            else:\n",
    "                occurences[wid][\"occurences\"] += 1\n",
    "                occurences[wid][\"prob\"] = max(occurences[wid][\"prob\"], w[0])\n",
    "    return [occurences,edges]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 18:52:24,769 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-07-18 18:52:24,773 : INFO : built Dictionary(1094 unique tokens: [u'extrapol', u'partial', u'hypopharyng', u'woodi', u'lack']...) from 58 documents (total 3027 corpus positions)\n",
      "2018-07-18 18:52:24,778 : INFO : saving Dictionary object under d:\\temp\\words.dict, separately None\n",
      "2018-07-18 18:52:24,780 : INFO : saved d:\\temp\\words.dict\n",
      "2018-07-18 18:52:24,783 : INFO : storing corpus in Matrix Market format to d:\\temp\\words.dict\n",
      "2018-07-18 18:52:24,786 : INFO : saving sparse matrix to d:\\temp\\words.dict\n",
      "2018-07-18 18:52:24,790 : INFO : PROGRESS: saving document #0\n",
      "2018-07-18 18:52:24,802 : INFO : saved 58x1094 matrix, density=3.399% (2157/63452)\n",
      "2018-07-18 18:52:24,805 : INFO : saving MmCorpus index to d:\\temp\\words.dict.index\n",
      "2018-07-18 18:52:24,811 : INFO : using symmetric alpha at 0.00444444444444\n",
      "2018-07-18 18:52:24,815 : INFO : using symmetric eta at 0.00444444444444\n",
      "2018-07-18 18:52:24,816 : INFO : using serial LDA version on this node\n",
      "2018-07-18 18:52:24,848 : INFO : running online (multi-pass) LDA training, 225 topics, 75 passes over the supplied corpus of 58 documents, updating model once every 58 documents, evaluating perplexity every 58 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-07-18 18:52:25,006 : INFO : -322.082 per-word bound, 9044766391580239301899560805612409735406041396557777951952451137620267946024450549469008743104512.0 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:25,009 : INFO : PROGRESS: pass 0, at document #58/58\n",
      "2018-07-18 18:52:25,164 : INFO : topic #154 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,164 : INFO : topic #35 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,167 : INFO : topic #170 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,167 : INFO : topic #160 (0.004): 0.044*\"hair\" + 0.044*\"pump\" + 0.044*\"intak\" + 0.044*\"retract\" + 0.044*\"account\" + 0.044*\"1964\" + 0.044*\"process\" + 0.044*\"mechan\" + 0.044*\"describ\" + 0.044*\"salivari\"\n",
      "2018-07-18 18:52:25,170 : INFO : topic #223 (0.004): 0.065*\"mice\" + 0.065*\"prior\" + 0.065*\"day\" + 0.065*\"white\" + 0.065*\"period\" + 0.065*\"inject\" + 0.065*\"venom\" + 0.065*\"death\" + 0.033*\"starvat\" + 0.033*\"fed\"\n",
      "2018-07-18 18:52:25,171 : INFO : topic diff=215.734634, rho=1.000000\n",
      "2018-07-18 18:52:25,243 : INFO : -10.023 per-word bound, 1040.6 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:25,246 : INFO : PROGRESS: pass 1, at document #58/58\n",
      "2018-07-18 18:52:25,322 : INFO : topic #116 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,325 : INFO : topic #57 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,326 : INFO : topic #142 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,328 : INFO : topic #35 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,329 : INFO : topic #93 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,331 : INFO : topic diff=inf, rho=0.577350\n",
      "2018-07-18 18:52:25,398 : INFO : -9.275 per-word bound, 619.6 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:25,401 : INFO : PROGRESS: pass 2, at document #58/58\n",
      "2018-07-18 18:52:25,470 : INFO : topic #136 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,473 : INFO : topic #48 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,476 : INFO : topic #73 (0.004): 0.013*\"rear\" + 0.011*\"swarm\" + 0.010*\"queen\" + 0.007*\"brood\" + 0.006*\"occur\" + 0.005*\"maximum\" + 0.004*\"reach\" + 0.004*\"began\" + 0.004*\"actual\" + 0.004*\"seem\"\n",
      "2018-07-18 18:52:25,476 : INFO : topic #20 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,477 : INFO : topic #174 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,480 : INFO : topic diff=inf, rho=0.500000\n",
      "2018-07-18 18:52:25,549 : INFO : -8.758 per-word bound, 432.9 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:25,552 : INFO : PROGRESS: pass 3, at document #58/58\n",
      "2018-07-18 18:52:25,622 : INFO : topic #142 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,625 : INFO : topic #115 (0.004): 0.060*\"work\" + 0.060*\"partial\" + 0.060*\"temperatur\" + 0.060*\"group\" + 0.060*\"repeat\" + 0.060*\"1961\" + 0.060*\"brought\" + 0.060*\"european\" + 0.060*\"recent\" + 0.060*\"publish\"\n",
      "2018-07-18 18:52:25,625 : INFO : topic #117 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,627 : INFO : topic #137 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,628 : INFO : topic #200 (0.004): 0.156*\"swarm\" + 0.117*\"coloni\" + 0.039*\"abscond\" + 0.026*\"went\" + 0.026*\"crowd\" + 0.026*\"old\" + 0.026*\"less\" + 0.013*\"like\" + 0.013*\"comb\" + 0.013*\"part\"\n",
      "2018-07-18 18:52:25,630 : INFO : topic diff=inf, rho=0.447214\n",
      "2018-07-18 18:52:25,696 : INFO : -8.362 per-word bound, 329.1 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:25,697 : INFO : PROGRESS: pass 4, at document #58/58\n",
      "2018-07-18 18:52:25,767 : INFO : topic #192 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,770 : INFO : topic #18 (0.004): 0.047*\"larval\" + 0.047*\"queen\" + 0.037*\"protein\" + 0.037*\"deriv\" + 0.028*\"cell\" + 0.028*\"royal\" + 0.028*\"jelli\" + 0.028*\"compon\" + 0.028*\"decano\" + 0.019*\"given\"\n",
      "2018-07-18 18:52:25,772 : INFO : topic #39 (0.004): 0.075*\"drone\" + 0.050*\"worker\" + 0.041*\"temperatur\" + 0.033*\"period\" + 0.025*\"old\" + 0.025*\"feed\" + 0.025*\"day\" + 0.025*\"chillcoma\" + 0.017*\"behaviour\" + 0.017*\"entir\"\n",
      "2018-07-18 18:52:25,773 : INFO : topic #212 (0.004): 0.119*\"protein\" + 0.071*\"venom\" + 0.048*\"differ\" + 0.047*\"demonstr\" + 0.024*\"mean\" + 0.024*\"1965\" + 0.024*\"pattern\" + 0.024*\"comparison\" + 0.024*\"louisiana\" + 0.024*\"entir\"\n",
      "2018-07-18 18:52:25,775 : INFO : topic #57 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,776 : INFO : topic diff=inf, rho=0.408248\n",
      "2018-07-18 18:52:25,845 : INFO : -8.066 per-word bound, 268.0 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:25,845 : INFO : PROGRESS: pass 5, at document #58/58\n",
      "2018-07-18 18:52:25,915 : INFO : topic #20 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,918 : INFO : topic #29 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,920 : INFO : topic #23 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,921 : INFO : topic #201 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:25,923 : INFO : topic #82 (0.004): 0.014*\"sarcosom\" + 0.010*\"mixtur\" + 0.010*\"oxid\" + 0.010*\"incub\" + 0.009*\"reaction\" + 0.008*\"respiratori\" + 0.007*\"addit\" + 0.007*\"adp\" + 0.006*\"stimul\" + 0.005*\"cytochrom\"\n",
      "2018-07-18 18:52:25,924 : INFO : topic diff=inf, rho=0.377964\n",
      "2018-07-18 18:52:25,994 : INFO : -7.846 per-word bound, 230.1 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:25,996 : INFO : PROGRESS: pass 6, at document #58/58\n",
      "2018-07-18 18:52:26,068 : INFO : topic #16 (0.004): 0.128*\"entranc\" + 0.103*\"day\" + 0.077*\"close\" + 0.077*\"sampl\" + 0.052*\"open\" + 0.051*\"infect\" + 0.026*\"linnaeu\" + 0.026*\"determin\" + 0.026*\"discuss\" + 0.026*\"1965\"\n",
      "2018-07-18 18:52:26,069 : INFO : topic #53 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,069 : INFO : topic #90 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,072 : INFO : topic #178 (0.004): 0.070*\"rear\" + 0.058*\"queen\" + 0.056*\"swarm\" + 0.036*\"brood\" + 0.035*\"occur\" + 0.026*\"maximum\" + 0.018*\"seem\" + 0.018*\"breed\" + 0.018*\"season\" + 0.018*\"prepar\"\n",
      "2018-07-18 18:52:26,076 : INFO : topic #203 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,078 : INFO : topic diff=inf, rho=0.353553\n",
      "2018-07-18 18:52:26,144 : INFO : -7.686 per-word bound, 206.0 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:26,147 : INFO : PROGRESS: pass 7, at document #58/58\n",
      "2018-07-18 18:52:26,216 : INFO : topic #65 (0.004): 0.143*\"vitamin\" + 0.061*\"head\" + 0.041*\"demonstr\" + 0.041*\"extract\" + 0.021*\"magnesium\" + 0.021*\"identifi\" + 0.021*\"method\" + 0.021*\"experi\" + 0.021*\"chlorid\" + 0.021*\"littl\"\n",
      "2018-07-18 18:52:26,217 : INFO : topic #217 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,219 : INFO : topic #47 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,220 : INFO : topic #184 (0.004): 0.002*\"nutrit\" + 0.002*\"phase\" + 0.002*\"factor\" + 0.001*\"establish\" + 0.001*\"cast\" + 0.001*\"larval\" + 0.001*\"day\" + 0.001*\"differ\" + 0.001*\"fourth\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:26,221 : INFO : topic #46 (0.004): 0.006*\"eye\" + 0.005*\"compound\" + 0.004*\"flicker\" + 0.004*\"erg\" + 0.003*\"frequenc\" + 0.003*\"fusion\" + 0.003*\"ocellu\" + 0.003*\"form\" + 0.003*\"sensit\" + 0.003*\"suggest\"\n",
      "2018-07-18 18:52:26,223 : INFO : topic diff=inf, rho=0.333333\n",
      "2018-07-18 18:52:26,292 : INFO : -7.572 per-word bound, 190.3 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:26,295 : INFO : PROGRESS: pass 8, at document #58/58\n",
      "2018-07-18 18:52:26,368 : INFO : topic #128 (0.004): 0.002*\"site\" + 0.002*\"old\" + 0.001*\"first\" + 0.001*\"new\" + 0.001*\"coloni\" + 0.001*\"visit\" + 0.001*\"return\" + 0.001*\"distanc\" + 0.001*\"move\" + 0.001*\"third\"\n",
      "2018-07-18 18:52:26,371 : INFO : topic #220 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,371 : INFO : topic #47 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,375 : INFO : topic #149 (0.004): 0.003*\"cast\" + 0.003*\"nutrit\" + 0.003*\"factor\" + 0.003*\"phase\" + 0.002*\"establish\" + 0.002*\"larval\" + 0.002*\"hormon\" + 0.002*\"suggest\" + 0.002*\"initi\" + 0.002*\"life\"\n",
      "2018-07-18 18:52:26,377 : INFO : topic #135 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,378 : INFO : topic diff=inf, rho=0.316228\n",
      "2018-07-18 18:52:26,448 : INFO : -7.493 per-word bound, 180.1 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:26,450 : INFO : PROGRESS: pass 9, at document #58/58\n",
      "2018-07-18 18:52:26,520 : INFO : topic #6 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,523 : INFO : topic #52 (0.004): 0.001*\"paralysi\" + 0.001*\"viru\" + 0.001*\"particl\" + 0.001*\"wherea\" + 0.001*\"cbpv\" + 0.001*\"healthi\" + 0.001*\"chronic\" + 0.001*\"caus\" + 0.001*\"abpv\" + 0.001*\"day\"\n",
      "2018-07-18 18:52:26,525 : INFO : topic #95 (0.004): 0.088*\"eye\" + 0.058*\"compound\" + 0.058*\"flicker\" + 0.049*\"erg\" + 0.039*\"frequenc\" + 0.039*\"fusion\" + 0.029*\"ocellu\" + 0.029*\"wave\" + 0.029*\"form\" + 0.029*\"sensit\"\n",
      "2018-07-18 18:52:26,526 : INFO : topic #102 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,528 : INFO : topic #193 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,529 : INFO : topic diff=inf, rho=0.301511\n",
      "2018-07-18 18:52:26,595 : INFO : -7.438 per-word bound, 173.4 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:26,598 : INFO : PROGRESS: pass 10, at document #58/58\n",
      "2018-07-18 18:52:26,667 : INFO : topic #48 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,670 : INFO : topic #75 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,671 : INFO : topic #85 (0.004): 0.082*\"queen\" + 0.055*\"swarm\" + 0.055*\"soon\" + 0.041*\"fli\" + 0.028*\"disturb\" + 0.028*\"taken\" + 0.028*\"cluster\" + 0.027*\"coloni\" + 0.027*\"hive\" + 0.027*\"return\"\n",
      "2018-07-18 18:52:26,671 : INFO : topic #219 (0.004): 0.139*\"site\" + 0.096*\"old\" + 0.064*\"new\" + 0.053*\"coloni\" + 0.043*\"return\" + 0.043*\"visit\" + 0.043*\"first\" + 0.032*\"move\" + 0.032*\"distanc\" + 0.021*\"near\"\n",
      "2018-07-18 18:52:26,674 : INFO : topic #77 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,674 : INFO : topic diff=inf, rho=0.288675\n",
      "2018-07-18 18:52:26,743 : INFO : -7.400 per-word bound, 168.9 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:26,746 : INFO : PROGRESS: pass 11, at document #58/58\n",
      "2018-07-18 18:52:26,816 : INFO : topic #161 (0.004): 0.001*\"deriv\" + 0.001*\"relationship\" + 0.001*\"decano\" + 0.001*\"describ\" + 0.001*\"chromatograph\" + 0.001*\"conduct\" + 0.001*\"form\" + 0.001*\"column\" + 0.001*\"compon\" + 0.001*\"addit\"\n",
      "2018-07-18 18:52:26,818 : INFO : topic #110 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,819 : INFO : topic #77 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,821 : INFO : topic #188 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,822 : INFO : topic #135 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,826 : INFO : topic diff=inf, rho=0.277350\n",
      "2018-07-18 18:52:26,900 : INFO : -7.375 per-word bound, 166.0 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:26,901 : INFO : PROGRESS: pass 12, at document #58/58\n",
      "2018-07-18 18:52:26,974 : INFO : topic #218 (0.004): 0.072*\"semen\" + 0.072*\"insemin\" + 0.036*\"mail\" + 0.036*\"describ\" + 0.036*\"success\" + 0.036*\"store\" + 0.036*\"obtain\" + 0.036*\"storag\" + 0.036*\"egg\" + 0.036*\"temperatur\"\n",
      "2018-07-18 18:52:26,977 : INFO : topic #23 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,979 : INFO : topic #36 (0.004): 0.051*\"extract\" + 0.032*\"prepar\" + 0.025*\"type\" + 0.025*\"bodi\" + 0.019*\"compon\" + 0.019*\"whole\" + 0.019*\"allergen\" + 0.019*\"determin\" + 0.019*\"venom\" + 0.013*\"muscl\"\n",
      "2018-07-18 18:52:26,980 : INFO : topic #214 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:26,982 : INFO : topic #38 (0.004): 0.001*\"drone\" + 0.001*\"worker\" + 0.001*\"period\" + 0.001*\"attack\" + 0.001*\"observ\" + 0.001*\"day\" + 0.001*\"feed\" + 0.001*\"old\" + 0.001*\"although\" + 0.001*\"insid\"\n",
      "2018-07-18 18:52:26,983 : INFO : topic diff=inf, rho=0.267261\n",
      "2018-07-18 18:52:27,051 : INFO : -7.357 per-word bound, 164.0 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:27,052 : INFO : PROGRESS: pass 13, at document #58/58\n",
      "2018-07-18 18:52:27,122 : INFO : topic #63 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,125 : INFO : topic #216 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,125 : INFO : topic #90 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,130 : INFO : topic #107 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,131 : INFO : topic #20 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,131 : INFO : topic diff=inf, rho=0.258199\n",
      "2018-07-18 18:52:27,203 : INFO : -7.346 per-word bound, 162.6 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:27,204 : INFO : PROGRESS: pass 14, at document #58/58\n",
      "2018-07-18 18:52:27,275 : INFO : topic #135 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,276 : INFO : topic #125 (0.004): 0.002*\"vitamin\" + 0.001*\"head\" + 0.001*\"venom\" + 0.001*\"hive\" + 0.001*\"extract\" + 0.001*\"provid\" + 0.001*\"demonstr\" + 0.001*\"enzym\" + 0.001*\"coloni\" + 0.001*\"chromatograph\"\n",
      "2018-07-18 18:52:27,279 : INFO : topic #29 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,280 : INFO : topic #169 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,282 : INFO : topic #165 (0.004): 0.097*\"worker\" + 0.085*\"lay\" + 0.048*\"queen\" + 0.036*\"remov\" + 0.036*\"day\" + 0.024*\"anatom\" + 0.024*\"reject\" + 0.024*\"larg\" + 0.024*\"dequeen\" + 0.024*\"spermatheca\"\n",
      "2018-07-18 18:52:27,283 : INFO : topic diff=inf, rho=0.250000\n",
      "2018-07-18 18:52:27,359 : INFO : -7.337 per-word bound, 161.7 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:27,361 : INFO : PROGRESS: pass 15, at document #58/58\n",
      "2018-07-18 18:52:27,433 : INFO : topic #127 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,436 : INFO : topic #97 (0.004): 0.144*\"queen\" + 0.115*\"attract\" + 0.057*\"secret\" + 0.057*\"gland\" + 0.057*\"virgin\" + 0.057*\"mate\" + 0.029*\"old\" + 0.029*\"assay\" + 0.029*\"termin\" + 0.029*\"describ\"\n",
      "2018-07-18 18:52:27,437 : INFO : topic #120 (0.004): 0.042*\"paralysi\" + 0.042*\"mite\" + 0.042*\"spray\" + 0.042*\"suspens\" + 0.042*\"pathogen\" + 0.042*\"normal\" + 0.042*\"acarapi\" + 0.042*\"suscept\" + 0.042*\"infest\" + 0.042*\"pseudomona\"\n",
      "2018-07-18 18:52:27,438 : INFO : topic #149 (0.004): 0.001*\"cast\" + 0.001*\"nutrit\" + 0.001*\"factor\" + 0.001*\"phase\" + 0.001*\"establish\" + 0.001*\"larval\" + 0.001*\"hormon\" + 0.001*\"suggest\" + 0.001*\"initi\" + 0.001*\"life\"\n",
      "2018-07-18 18:52:27,441 : INFO : topic #46 (0.004): 0.001*\"eye\" + 0.001*\"compound\" + 0.001*\"flicker\" + 0.001*\"erg\" + 0.001*\"frequenc\" + 0.001*\"fusion\" + 0.001*\"ocellu\" + 0.001*\"form\" + 0.001*\"sensit\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:27,444 : INFO : topic diff=inf, rho=0.242536\n",
      "2018-07-18 18:52:27,519 : INFO : -7.332 per-word bound, 161.1 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:27,522 : INFO : PROGRESS: pass 16, at document #58/58\n",
      "2018-07-18 18:52:27,594 : INFO : topic #30 (0.004): 0.001*\"publish\" + 0.001*\"egg\" + 0.001*\"cell\" + 0.001*\"pore\" + 0.001*\"structur\" + 0.001*\"group\" + 0.001*\"anterior\" + 0.001*\"prolong\" + 0.001*\"protoplasm\" + 0.001*\"consist\"\n",
      "2018-07-18 18:52:27,596 : INFO : topic #171 (0.004): 0.001*\"toxic\" + 0.001*\"temperatur\" + 0.001*\"carbam\" + 0.001*\"applic\" + 0.001*\"piperonyl\" + 0.001*\"butoxid\" + 0.001*\"suggest\" + 0.001*\"insecticid\" + 0.001*\"mechan\" + 0.001*\"time\"\n",
      "2018-07-18 18:52:27,598 : INFO : topic #61 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,599 : INFO : topic #133 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,601 : INFO : topic #150 (0.004): 0.086*\"mile\" + 0.052*\"locat\" + 0.052*\"distanc\" + 0.052*\"queen\" + 0.052*\"drone\" + 0.035*\"distant\" + 0.035*\"later\" + 0.035*\"lay\" + 0.035*\"101\" + 0.035*\"sourc\"\n",
      "2018-07-18 18:52:27,602 : INFO : topic diff=inf, rho=0.235702\n",
      "2018-07-18 18:52:27,674 : INFO : -7.328 per-word bound, 160.7 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:27,674 : INFO : PROGRESS: pass 17, at document #58/58\n",
      "2018-07-18 18:52:27,743 : INFO : topic #172 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,746 : INFO : topic #132 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,746 : INFO : topic #142 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,747 : INFO : topic #64 (0.004): 0.001*\"line\" + 0.001*\"larva\" + 0.001*\"virul\" + 0.001*\"resist\" + 0.001*\"suscept\" + 0.001*\"passag\" + 0.001*\"serial\" + 0.001*\"strain\" + 0.001*\"select\" + 0.001*\"spore\"\n",
      "2018-07-18 18:52:27,749 : INFO : topic #101 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,750 : INFO : topic diff=inf, rho=0.229416\n",
      "2018-07-18 18:52:27,818 : INFO : -7.325 per-word bound, 160.3 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:27,819 : INFO : PROGRESS: pass 18, at document #58/58\n",
      "2018-07-18 18:52:27,888 : INFO : topic #10 (0.004): 0.068*\"paralysi\" + 0.054*\"viru\" + 0.041*\"healthi\" + 0.041*\"cbpv\" + 0.041*\"particl\" + 0.027*\"acut\" + 0.027*\"abpv\" + 0.027*\"chronic\" + 0.027*\"occur\" + 0.027*\"infect\"\n",
      "2018-07-18 18:52:27,891 : INFO : topic #105 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,892 : INFO : topic #42 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,894 : INFO : topic #106 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:27,895 : INFO : topic #14 (0.004): 0.001*\"growth\" + 0.001*\"cytochrom\" + 0.001*\"pupal\" + 0.001*\"muscl\" + 0.001*\"progress\" + 0.001*\"wing\" + 0.001*\"discuss\" + 0.001*\"period\" + 0.001*\"flight\" + 0.001*\"associ\"\n",
      "2018-07-18 18:52:27,898 : INFO : topic diff=inf, rho=0.223607\n",
      "2018-07-18 18:52:27,964 : INFO : -7.323 per-word bound, 160.1 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:27,969 : INFO : PROGRESS: pass 19, at document #58/58\n",
      "2018-07-18 18:52:28,036 : INFO : topic #128 (0.004): 0.001*\"site\" + 0.001*\"old\" + 0.001*\"first\" + 0.001*\"new\" + 0.001*\"coloni\" + 0.001*\"visit\" + 0.001*\"return\" + 0.001*\"distanc\" + 0.001*\"move\" + 0.001*\"third\"\n",
      "2018-07-18 18:52:28,039 : INFO : topic #127 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,039 : INFO : topic #145 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,042 : INFO : topic #183 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,042 : INFO : topic #18 (0.004): 0.046*\"larval\" + 0.046*\"queen\" + 0.037*\"protein\" + 0.037*\"deriv\" + 0.028*\"cell\" + 0.028*\"royal\" + 0.028*\"jelli\" + 0.028*\"compon\" + 0.028*\"decano\" + 0.019*\"given\"\n",
      "2018-07-18 18:52:28,043 : INFO : topic diff=inf, rho=0.218218\n",
      "2018-07-18 18:52:28,111 : INFO : -7.322 per-word bound, 160.0 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:28,112 : INFO : PROGRESS: pass 20, at document #58/58\n",
      "2018-07-18 18:52:28,181 : INFO : topic #114 (0.004): 0.029*\"fed\" + 0.029*\"form\" + 0.029*\"compound\" + 0.029*\"right\" + 0.029*\"inhibit\" + 0.029*\"identifi\" + 0.029*\"metabolit\" + 0.029*\"specif\" + 0.029*\"queenless\" + 0.029*\"rapid\"\n",
      "2018-07-18 18:52:28,184 : INFO : topic #81 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,184 : INFO : topic #145 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,186 : INFO : topic #42 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,187 : INFO : topic #60 (0.004): 0.035*\"group\" + 0.035*\"now\" + 0.035*\"modif\" + 0.035*\"apparatu\" + 0.035*\"obtain\" + 0.035*\"copul\" + 0.035*\"part\" + 0.035*\"develop\" + 0.035*\"extern\" + 0.035*\"examin\"\n",
      "2018-07-18 18:52:28,190 : INFO : topic diff=inf, rho=0.213201\n",
      "2018-07-18 18:52:28,260 : INFO : -7.321 per-word bound, 159.8 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:28,263 : INFO : PROGRESS: pass 21, at document #58/58\n",
      "2018-07-18 18:52:28,334 : INFO : topic #119 (0.004): 0.046*\"male\" + 0.036*\"diploid\" + 0.027*\"indica\" + 0.027*\"show\" + 0.027*\"somat\" + 0.027*\"indian\" + 0.018*\"chromosom\" + 0.018*\"relat\" + 0.018*\"trigona\" + 0.018*\"multipl\"\n",
      "2018-07-18 18:52:28,336 : INFO : topic #222 (0.004): 0.097*\"cocoon\" + 0.058*\"larva\" + 0.039*\"materi\" + 0.039*\"made\" + 0.029*\"complet\" + 0.029*\"respect\" + 0.029*\"secret\" + 0.019*\"cell\" + 0.019*\"side\" + 0.019*\"wall\"\n",
      "2018-07-18 18:52:28,338 : INFO : topic #156 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,339 : INFO : topic #154 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,342 : INFO : topic #77 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,344 : INFO : topic diff=inf, rho=0.208514\n",
      "2018-07-18 18:52:28,417 : INFO : -7.320 per-word bound, 159.8 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:28,420 : INFO : PROGRESS: pass 22, at document #58/58\n",
      "2018-07-18 18:52:28,490 : INFO : topic #97 (0.004): 0.144*\"queen\" + 0.115*\"attract\" + 0.057*\"secret\" + 0.057*\"gland\" + 0.057*\"virgin\" + 0.057*\"mate\" + 0.029*\"old\" + 0.029*\"assay\" + 0.029*\"termin\" + 0.029*\"describ\"\n",
      "2018-07-18 18:52:28,493 : INFO : topic #0 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,494 : INFO : topic #91 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,497 : INFO : topic #169 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,500 : INFO : topic #29 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,500 : INFO : topic diff=inf, rho=0.204124\n",
      "2018-07-18 18:52:28,572 : INFO : -7.319 per-word bound, 159.7 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:28,575 : INFO : PROGRESS: pass 23, at document #58/58\n",
      "2018-07-18 18:52:28,644 : INFO : topic #115 (0.004): 0.060*\"work\" + 0.060*\"partial\" + 0.060*\"temperatur\" + 0.060*\"group\" + 0.060*\"repeat\" + 0.060*\"1961\" + 0.060*\"brought\" + 0.060*\"european\" + 0.060*\"recent\" + 0.060*\"publish\"\n",
      "2018-07-18 18:52:28,647 : INFO : topic #95 (0.004): 0.088*\"eye\" + 0.058*\"compound\" + 0.058*\"flicker\" + 0.049*\"erg\" + 0.039*\"frequenc\" + 0.039*\"fusion\" + 0.029*\"ocellu\" + 0.029*\"wave\" + 0.029*\"form\" + 0.029*\"sensit\"\n",
      "2018-07-18 18:52:28,648 : INFO : topic #153 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,650 : INFO : topic #173 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,651 : INFO : topic #15 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,653 : INFO : topic diff=inf, rho=0.200000\n",
      "2018-07-18 18:52:28,724 : INFO : -7.319 per-word bound, 159.6 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:28,726 : INFO : PROGRESS: pass 24, at document #58/58\n",
      "2018-07-18 18:52:28,798 : INFO : topic #140 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,801 : INFO : topic #141 (0.004): 0.001*\"queen\" + 0.001*\"attract\" + 0.001*\"mate\" + 0.001*\"virgin\" + 0.001*\"gland\" + 0.001*\"secret\" + 0.001*\"approxim\" + 0.001*\"caus\" + 0.001*\"remov\" + 0.001*\"mandibular\"\n",
      "2018-07-18 18:52:28,802 : INFO : topic #102 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,803 : INFO : topic #84 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,805 : INFO : topic #210 (0.004): 0.001*\"line\" + 0.001*\"larva\" + 0.001*\"virul\" + 0.001*\"passag\" + 0.001*\"resist\" + 0.001*\"suscept\" + 0.001*\"serial\" + 0.001*\"select\" + 0.001*\"result\" + 0.001*\"strain\"\n",
      "2018-07-18 18:52:28,806 : INFO : topic diff=inf, rho=0.196116\n",
      "2018-07-18 18:52:28,875 : INFO : -7.318 per-word bound, 159.6 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:28,878 : INFO : PROGRESS: pass 25, at document #58/58\n",
      "2018-07-18 18:52:28,947 : INFO : topic #209 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,950 : INFO : topic #155 (0.004): 0.132*\"queen\" + 0.066*\"nosema\" + 0.049*\"toler\" + 0.049*\"inocul\" + 0.033*\"sourc\" + 0.017*\"favor\" + 0.017*\"1963\" + 0.017*\"requir\" + 0.017*\"criterion\" + 0.017*\"lifespan\"\n",
      "2018-07-18 18:52:28,951 : INFO : topic #152 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:28,954 : INFO : topic #98 (0.004): 0.001*\"acet\" + 0.001*\"label\" + 0.001*\"feed\" + 0.001*\"cell\" + 0.001*\"fat\" + 0.001*\"acid\" + 0.001*\"origin\" + 0.001*\"uniformli\" + 0.001*\"wax\" + 0.001*\"heavi\"\n",
      "2018-07-18 18:52:28,957 : INFO : topic #210 (0.004): 0.001*\"line\" + 0.001*\"larva\" + 0.001*\"virul\" + 0.001*\"passag\" + 0.001*\"resist\" + 0.001*\"suscept\" + 0.001*\"serial\" + 0.001*\"select\" + 0.001*\"result\" + 0.001*\"strain\"\n",
      "2018-07-18 18:52:28,960 : INFO : topic diff=inf, rho=0.192450\n",
      "2018-07-18 18:52:29,032 : INFO : -7.318 per-word bound, 159.6 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:29,032 : INFO : PROGRESS: pass 26, at document #58/58\n",
      "2018-07-18 18:52:29,105 : INFO : topic #79 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,108 : INFO : topic #111 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,108 : INFO : topic #113 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,111 : INFO : topic #43 (0.004): 0.001*\"gland\" + 0.001*\"mandibular\" + 0.001*\"made\" + 0.001*\"sourc\" + 0.001*\"attract\" + 0.001*\"experi\" + 0.001*\"queen\" + 0.001*\"mate\" + 0.001*\"virgin\" + 0.001*\"discuss\"\n",
      "2018-07-18 18:52:29,112 : INFO : topic #183 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,115 : INFO : topic diff=inf, rho=0.188982\n",
      "2018-07-18 18:52:29,187 : INFO : -7.318 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:29,187 : INFO : PROGRESS: pass 27, at document #58/58\n",
      "2018-07-18 18:52:29,259 : INFO : topic #185 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,262 : INFO : topic #54 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,263 : INFO : topic #207 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,266 : INFO : topic #223 (0.004): 0.065*\"prior\" + 0.065*\"day\" + 0.065*\"white\" + 0.065*\"period\" + 0.065*\"inject\" + 0.065*\"venom\" + 0.065*\"mice\" + 0.065*\"death\" + 0.033*\"starvat\" + 0.033*\"fed\"\n",
      "2018-07-18 18:52:29,267 : INFO : topic #17 (0.004): 0.115*\"sting\" + 0.057*\"ball\" + 0.029*\"first\" + 0.029*\"hive\" + 0.029*\"odour\" + 0.029*\"carri\" + 0.029*\"substanc\" + 0.029*\"frequent\" + 0.029*\"natur\" + 0.029*\"publish\"\n",
      "2018-07-18 18:52:29,272 : INFO : topic diff=inf, rho=0.185695\n",
      "2018-07-18 18:52:29,348 : INFO : -7.318 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:29,349 : INFO : PROGRESS: pass 28, at document #58/58\n",
      "2018-07-18 18:52:29,420 : INFO : topic #107 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,424 : INFO : topic #195 (0.004): 0.001*\"queen\" + 0.001*\"fraction\" + 0.001*\"attract\" + 0.001*\"mate\" + 0.001*\"mandibular\" + 0.001*\"gland\" + 0.001*\"drone\" + 0.001*\"orient\" + 0.001*\"primari\" + 0.001*\"demonstr\"\n",
      "2018-07-18 18:52:29,424 : INFO : topic #173 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,426 : INFO : topic #76 (0.004): 0.102*\"normal\" + 0.061*\"cbpv\" + 0.061*\"paralysi\" + 0.041*\"inject\" + 0.041*\"viru\" + 0.041*\"natur\" + 0.041*\"chronic\" + 0.021*\"serolog\" + 0.021*\"britain\" + 0.021*\"spray\"\n",
      "2018-07-18 18:52:29,427 : INFO : topic #116 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,428 : INFO : topic diff=inf, rho=0.182574\n",
      "2018-07-18 18:52:29,497 : INFO : -7.318 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:29,499 : INFO : PROGRESS: pass 29, at document #58/58\n",
      "2018-07-18 18:52:29,566 : INFO : topic #120 (0.004): 0.042*\"paralysi\" + 0.042*\"mite\" + 0.042*\"spray\" + 0.042*\"suspens\" + 0.042*\"pathogen\" + 0.042*\"normal\" + 0.042*\"acarapi\" + 0.042*\"suscept\" + 0.042*\"infest\" + 0.042*\"pseudomona\"\n",
      "2018-07-18 18:52:29,569 : INFO : topic #94 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,571 : INFO : topic #22 (0.004): 0.001*\"lay\" + 0.001*\"worker\" + 0.001*\"queen\" + 0.001*\"day\" + 0.001*\"spermatheca\" + 0.001*\"larg\" + 0.001*\"remov\" + 0.001*\"anatom\" + 0.001*\"dequeen\" + 0.001*\"reject\"\n",
      "2018-07-18 18:52:29,572 : INFO : topic #87 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,576 : INFO : topic #43 (0.004): 0.001*\"gland\" + 0.001*\"mandibular\" + 0.001*\"made\" + 0.001*\"sourc\" + 0.001*\"attract\" + 0.001*\"experi\" + 0.001*\"queen\" + 0.001*\"mate\" + 0.001*\"virgin\" + 0.001*\"discuss\"\n",
      "2018-07-18 18:52:29,578 : INFO : topic diff=inf, rho=0.179605\n",
      "2018-07-18 18:52:29,647 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:29,648 : INFO : PROGRESS: pass 30, at document #58/58\n",
      "2018-07-18 18:52:29,720 : INFO : topic #149 (0.004): 0.001*\"cast\" + 0.001*\"nutrit\" + 0.001*\"factor\" + 0.001*\"phase\" + 0.001*\"establish\" + 0.001*\"larval\" + 0.001*\"hormon\" + 0.001*\"suggest\" + 0.001*\"initi\" + 0.001*\"life\"\n",
      "2018-07-18 18:52:29,721 : INFO : topic #60 (0.004): 0.035*\"group\" + 0.035*\"now\" + 0.035*\"modif\" + 0.035*\"apparatu\" + 0.035*\"obtain\" + 0.035*\"copul\" + 0.035*\"part\" + 0.035*\"develop\" + 0.035*\"extern\" + 0.035*\"examin\"\n",
      "2018-07-18 18:52:29,723 : INFO : topic #104 (0.004): 0.001*\"reaction\" + 0.001*\"posit\" + 0.001*\"person\" + 0.001*\"per\" + 0.001*\"cent\" + 0.001*\"extract\" + 0.001*\"neg\" + 0.001*\"test\" + 0.001*\"skin\" + 0.001*\"normal\"\n",
      "2018-07-18 18:52:29,724 : INFO : topic #6 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,726 : INFO : topic #15 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,727 : INFO : topic diff=inf, rho=0.176777\n",
      "2018-07-18 18:52:29,796 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:29,799 : INFO : PROGRESS: pass 31, at document #58/58\n",
      "2018-07-18 18:52:29,872 : INFO : topic #52 (0.004): 0.001*\"paralysi\" + 0.001*\"viru\" + 0.001*\"particl\" + 0.001*\"wherea\" + 0.001*\"cbpv\" + 0.001*\"healthi\" + 0.001*\"chronic\" + 0.001*\"caus\" + 0.001*\"abpv\" + 0.001*\"day\"\n",
      "2018-07-18 18:52:29,875 : INFO : topic #74 (0.004): 0.001*\"entranc\" + 0.001*\"day\" + 0.001*\"sampl\" + 0.001*\"close\" + 0.001*\"infect\" + 0.001*\"open\" + 0.001*\"produc\" + 0.001*\"compar\" + 0.001*\"made\" + 0.001*\"period\"\n",
      "2018-07-18 18:52:29,875 : INFO : topic #85 (0.004): 0.082*\"queen\" + 0.055*\"swarm\" + 0.055*\"soon\" + 0.041*\"fli\" + 0.028*\"disturb\" + 0.028*\"taken\" + 0.028*\"cluster\" + 0.028*\"coloni\" + 0.028*\"hive\" + 0.028*\"return\"\n",
      "2018-07-18 18:52:29,877 : INFO : topic #143 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:29,878 : INFO : topic #118 (0.004): 0.001*\"cytochrom\" + 0.001*\"progress\" + 0.001*\"growth\" + 0.001*\"wing\" + 0.001*\"pupal\" + 0.001*\"muscl\" + 0.001*\"sarcosom\" + 0.001*\"flight\" + 0.001*\"associ\" + 0.001*\"period\"\n",
      "2018-07-18 18:52:29,880 : INFO : topic diff=inf, rho=0.174078\n",
      "2018-07-18 18:52:29,950 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:29,951 : INFO : PROGRESS: pass 32, at document #58/58\n",
      "2018-07-18 18:52:30,020 : INFO : topic #0 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,025 : INFO : topic #28 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,026 : INFO : topic #130 (0.004): 0.001*\"swarm\" + 0.001*\"coloni\" + 0.001*\"abscond\" + 0.001*\"less\" + 0.001*\"old\" + 0.001*\"went\" + 0.001*\"crowd\" + 0.001*\"held\" + 0.001*\"behaviour\" + 0.001*\"inclin\"\n",
      "2018-07-18 18:52:30,029 : INFO : topic #120 (0.004): 0.042*\"paralysi\" + 0.042*\"mite\" + 0.042*\"spray\" + 0.042*\"suspens\" + 0.042*\"pathogen\" + 0.042*\"normal\" + 0.042*\"acarapi\" + 0.042*\"suscept\" + 0.042*\"infest\" + 0.042*\"pseudomona\"\n",
      "2018-07-18 18:52:30,029 : INFO : topic #123 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,030 : INFO : topic diff=inf, rho=0.171499\n",
      "2018-07-18 18:52:30,101 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:30,102 : INFO : PROGRESS: pass 33, at document #58/58\n",
      "2018-07-18 18:52:30,173 : INFO : topic #14 (0.004): 0.001*\"growth\" + 0.001*\"cytochrom\" + 0.001*\"pupal\" + 0.001*\"muscl\" + 0.001*\"progress\" + 0.001*\"wing\" + 0.001*\"discuss\" + 0.001*\"period\" + 0.001*\"flight\" + 0.001*\"associ\"\n",
      "2018-07-18 18:52:30,176 : INFO : topic #183 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,177 : INFO : topic #144 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,178 : INFO : topic #208 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,180 : INFO : topic #189 (0.004): 0.001*\"temperatur\" + 0.001*\"chillcoma\" + 0.001*\"lower\" + 0.001*\"summer\" + 0.001*\"10°\" + 0.001*\"35°\" + 0.001*\"decreas\" + 0.001*\"consumpt\" + 0.001*\"differ\" + 0.001*\"influenc\"\n",
      "2018-07-18 18:52:30,181 : INFO : topic diff=inf, rho=0.169031\n",
      "2018-07-18 18:52:30,250 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:30,253 : INFO : PROGRESS: pass 34, at document #58/58\n",
      "2018-07-18 18:52:30,326 : INFO : topic #133 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,328 : INFO : topic #166 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,329 : INFO : topic #142 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,331 : INFO : topic #114 (0.004): 0.029*\"fed\" + 0.029*\"form\" + 0.029*\"compound\" + 0.029*\"inhibit\" + 0.029*\"right\" + 0.029*\"identifi\" + 0.029*\"specif\" + 0.029*\"metabolit\" + 0.029*\"queenless\" + 0.029*\"physiolog\"\n",
      "2018-07-18 18:52:30,332 : INFO : topic #117 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,334 : INFO : topic diff=inf, rho=0.166667\n",
      "2018-07-18 18:52:30,404 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:30,407 : INFO : PROGRESS: pass 35, at document #58/58\n",
      "2018-07-18 18:52:30,483 : INFO : topic #122 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,486 : INFO : topic #36 (0.004): 0.051*\"extract\" + 0.032*\"prepar\" + 0.025*\"type\" + 0.025*\"bodi\" + 0.019*\"compon\" + 0.019*\"whole\" + 0.019*\"allergen\" + 0.019*\"determin\" + 0.019*\"venom\" + 0.013*\"muscl\"\n",
      "2018-07-18 18:52:30,486 : INFO : topic #115 (0.004): 0.060*\"work\" + 0.060*\"partial\" + 0.060*\"temperatur\" + 0.060*\"group\" + 0.060*\"repeat\" + 0.060*\"1961\" + 0.060*\"brought\" + 0.060*\"european\" + 0.060*\"recent\" + 0.060*\"publish\"\n",
      "2018-07-18 18:52:30,490 : INFO : topic #143 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,492 : INFO : topic #20 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,493 : INFO : topic diff=inf, rho=0.164399\n",
      "2018-07-18 18:52:30,562 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:30,563 : INFO : PROGRESS: pass 36, at document #58/58\n",
      "2018-07-18 18:52:30,635 : INFO : topic #72 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,638 : INFO : topic #86 (0.004): 0.001*\"appear\" + 0.001*\"particl\" + 0.001*\"reaction\" + 0.001*\"sacbrood\" + 0.001*\"nucleic\" + 0.001*\"linnaeu\" + 0.001*\"phenol\" + 0.001*\"prepar\" + 0.001*\"determin\" + 0.001*\"viru\"\n",
      "2018-07-18 18:52:30,642 : INFO : topic #38 (0.004): 0.001*\"drone\" + 0.001*\"worker\" + 0.001*\"period\" + 0.001*\"attack\" + 0.001*\"observ\" + 0.001*\"day\" + 0.001*\"feed\" + 0.001*\"old\" + 0.001*\"although\" + 0.001*\"insid\"\n",
      "2018-07-18 18:52:30,645 : INFO : topic #178 (0.004): 0.070*\"rear\" + 0.061*\"queen\" + 0.061*\"swarm\" + 0.035*\"brood\" + 0.035*\"occur\" + 0.026*\"maximum\" + 0.017*\"seem\" + 0.017*\"breed\" + 0.017*\"season\" + 0.017*\"prepar\"\n",
      "2018-07-18 18:52:30,648 : INFO : topic #19 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,648 : INFO : topic diff=inf, rho=0.162221\n",
      "2018-07-18 18:52:30,717 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:30,720 : INFO : PROGRESS: pass 37, at document #58/58\n",
      "2018-07-18 18:52:30,792 : INFO : topic #150 (0.004): 0.086*\"mile\" + 0.052*\"locat\" + 0.052*\"distanc\" + 0.052*\"queen\" + 0.052*\"drone\" + 0.035*\"distant\" + 0.035*\"later\" + 0.035*\"lay\" + 0.035*\"101\" + 0.035*\"sourc\"\n",
      "2018-07-18 18:52:30,795 : INFO : topic #136 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,796 : INFO : topic #36 (0.004): 0.051*\"extract\" + 0.032*\"prepar\" + 0.025*\"type\" + 0.025*\"bodi\" + 0.019*\"compon\" + 0.019*\"whole\" + 0.019*\"allergen\" + 0.019*\"determin\" + 0.019*\"venom\" + 0.013*\"muscl\"\n",
      "2018-07-18 18:52:30,799 : INFO : topic #98 (0.004): 0.001*\"acet\" + 0.001*\"label\" + 0.001*\"feed\" + 0.001*\"cell\" + 0.001*\"fat\" + 0.001*\"acid\" + 0.001*\"origin\" + 0.001*\"uniformli\" + 0.001*\"wax\" + 0.001*\"heavi\"\n",
      "2018-07-18 18:52:30,799 : INFO : topic #192 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,802 : INFO : topic diff=inf, rho=0.160128\n",
      "2018-07-18 18:52:30,874 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:30,875 : INFO : PROGRESS: pass 38, at document #58/58\n",
      "2018-07-18 18:52:30,947 : INFO : topic #137 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,950 : INFO : topic #14 (0.004): 0.001*\"growth\" + 0.001*\"cytochrom\" + 0.001*\"pupal\" + 0.001*\"muscl\" + 0.001*\"progress\" + 0.001*\"wing\" + 0.001*\"discuss\" + 0.001*\"period\" + 0.001*\"flight\" + 0.001*\"associ\"\n",
      "2018-07-18 18:52:30,951 : INFO : topic #169 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,953 : INFO : topic #216 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:30,954 : INFO : topic #221 (0.004): 0.102*\"sternit\" + 0.068*\"size\" + 0.051*\"abdomin\" + 0.051*\"measur\" + 0.051*\"length\" + 0.051*\"width\" + 0.034*\"differ\" + 0.034*\"microscop\" + 0.017*\"taylor\" + 0.017*\"hand\"\n",
      "2018-07-18 18:52:30,957 : INFO : topic diff=inf, rho=0.158114\n",
      "2018-07-18 18:52:31,025 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:31,026 : INFO : PROGRESS: pass 39, at document #58/58\n",
      "2018-07-18 18:52:31,095 : INFO : topic #128 (0.004): 0.001*\"site\" + 0.001*\"old\" + 0.001*\"first\" + 0.001*\"new\" + 0.001*\"coloni\" + 0.001*\"visit\" + 0.001*\"return\" + 0.001*\"distanc\" + 0.001*\"move\" + 0.001*\"third\"\n",
      "2018-07-18 18:52:31,099 : INFO : topic #111 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,101 : INFO : topic #202 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,101 : INFO : topic #75 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,102 : INFO : topic #88 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,105 : INFO : topic diff=inf, rho=0.156174\n",
      "2018-07-18 18:52:31,171 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:31,174 : INFO : PROGRESS: pass 40, at document #58/58\n",
      "2018-07-18 18:52:31,246 : INFO : topic #69 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,249 : INFO : topic #61 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,250 : INFO : topic #194 (0.004): 0.001*\"day\" + 0.001*\"entranc\" + 0.001*\"close\" + 0.001*\"sampl\" + 0.001*\"infect\" + 0.001*\"open\" + 0.001*\"examin\" + 0.001*\"produc\" + 0.001*\"time\" + 0.001*\"made\"\n",
      "2018-07-18 18:52:31,252 : INFO : topic #196 (0.004): 0.001*\"cast\" + 0.001*\"factor\" + 0.001*\"nutrit\" + 0.001*\"phase\" + 0.001*\"larval\" + 0.001*\"establish\" + 0.001*\"relat\" + 0.001*\"dimorph\" + 0.001*\"differ\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:31,253 : INFO : topic #129 (0.004): 0.070*\"mandibular\" + 0.070*\"gland\" + 0.047*\"experi\" + 0.047*\"mate\" + 0.047*\"queen\" + 0.047*\"made\" + 0.047*\"sourc\" + 0.047*\"virgin\" + 0.047*\"attract\" + 0.023*\"report\"\n",
      "2018-07-18 18:52:31,255 : INFO : topic diff=inf, rho=0.154303\n",
      "2018-07-18 18:52:31,325 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:31,328 : INFO : PROGRESS: pass 41, at document #58/58\n",
      "2018-07-18 18:52:31,400 : INFO : topic #152 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,401 : INFO : topic #167 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,403 : INFO : topic #177 (0.004): 0.140*\"viru\" + 0.056*\"tissu\" + 0.056*\"cbpv\" + 0.028*\"locat\" + 0.028*\"compar\" + 0.028*\"muscl\" + 0.028*\"chronic\" + 0.028*\"reveal\" + 0.028*\"healthi\" + 0.028*\"thin\"\n",
      "2018-07-18 18:52:31,407 : INFO : topic #122 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,407 : INFO : topic #182 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,410 : INFO : topic diff=inf, rho=0.152499\n",
      "2018-07-18 18:52:31,480 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:31,482 : INFO : PROGRESS: pass 42, at document #58/58\n",
      "2018-07-18 18:52:31,551 : INFO : topic #154 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,555 : INFO : topic #98 (0.004): 0.001*\"acet\" + 0.001*\"label\" + 0.001*\"feed\" + 0.001*\"cell\" + 0.001*\"fat\" + 0.001*\"acid\" + 0.001*\"origin\" + 0.001*\"uniformli\" + 0.001*\"wax\" + 0.001*\"heavi\"\n",
      "2018-07-18 18:52:31,555 : INFO : topic #69 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,556 : INFO : topic #116 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,559 : INFO : topic #212 (0.004): 0.122*\"protein\" + 0.074*\"venom\" + 0.049*\"differ\" + 0.049*\"demonstr\" + 0.025*\"mean\" + 0.025*\"1965\" + 0.025*\"pure\" + 0.025*\"content\" + 0.025*\"extract\" + 0.025*\"incorpor\"\n",
      "2018-07-18 18:52:31,559 : INFO : topic diff=inf, rho=0.150756\n",
      "2018-07-18 18:52:31,625 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:31,628 : INFO : PROGRESS: pass 43, at document #58/58\n",
      "2018-07-18 18:52:31,698 : INFO : topic #52 (0.004): 0.001*\"paralysi\" + 0.001*\"viru\" + 0.001*\"wherea\" + 0.001*\"particl\" + 0.001*\"cbpv\" + 0.001*\"healthi\" + 0.001*\"chronic\" + 0.001*\"caus\" + 0.001*\"abpv\" + 0.001*\"day\"\n",
      "2018-07-18 18:52:31,700 : INFO : topic #91 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,703 : INFO : topic #49 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,704 : INFO : topic #182 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,706 : INFO : topic #152 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,709 : INFO : topic diff=inf, rho=0.149071\n",
      "2018-07-18 18:52:31,776 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:31,780 : INFO : PROGRESS: pass 44, at document #58/58\n",
      "2018-07-18 18:52:31,849 : INFO : topic #57 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,851 : INFO : topic #37 (0.004): 0.001*\"queen\" + 0.001*\"soon\" + 0.001*\"swarm\" + 0.001*\"fli\" + 0.001*\"return\" + 0.001*\"hive\" + 0.001*\"coloni\" + 0.001*\"cluster\" + 0.001*\"taken\" + 0.001*\"disturb\"\n",
      "2018-07-18 18:52:31,852 : INFO : topic #15 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:31,855 : INFO : topic #103 (0.004): 0.135*\"line\" + 0.095*\"larva\" + 0.081*\"virul\" + 0.068*\"suscept\" + 0.068*\"resist\" + 0.068*\"passag\" + 0.054*\"serial\" + 0.041*\"strain\" + 0.041*\"select\" + 0.027*\"result\"\n",
      "2018-07-18 18:52:31,855 : INFO : topic #21 (0.004): 0.001*\"insemin\" + 0.001*\"semen\" + 0.001*\"vitro\" + 0.001*\"experiment\" + 0.001*\"fertil\" + 0.001*\"queen\" + 0.001*\"treatment\" + 0.001*\"day\" + 0.001*\"variou\" + 0.001*\"ordinari\"\n",
      "2018-07-18 18:52:31,857 : INFO : topic diff=inf, rho=0.147442\n",
      "2018-07-18 18:52:31,928 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:31,930 : INFO : PROGRESS: pass 45, at document #58/58\n",
      "2018-07-18 18:52:32,000 : INFO : topic #74 (0.004): 0.001*\"entranc\" + 0.001*\"day\" + 0.001*\"sampl\" + 0.001*\"close\" + 0.001*\"infect\" + 0.001*\"open\" + 0.001*\"produc\" + 0.001*\"compar\" + 0.001*\"made\" + 0.001*\"period\"\n",
      "2018-07-18 18:52:32,002 : INFO : topic #113 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,003 : INFO : topic #15 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,005 : INFO : topic #182 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,006 : INFO : topic #150 (0.004): 0.086*\"mile\" + 0.052*\"locat\" + 0.052*\"distanc\" + 0.052*\"queen\" + 0.052*\"drone\" + 0.035*\"later\" + 0.035*\"distant\" + 0.035*\"sourc\" + 0.035*\"lay\" + 0.035*\"101\"\n",
      "2018-07-18 18:52:32,006 : INFO : topic diff=inf, rho=0.145865\n",
      "2018-07-18 18:52:32,075 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:32,076 : INFO : PROGRESS: pass 46, at document #58/58\n",
      "2018-07-18 18:52:32,147 : INFO : topic #2 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,150 : INFO : topic #65 (0.004): 0.143*\"vitamin\" + 0.061*\"head\" + 0.041*\"demonstr\" + 0.041*\"extract\" + 0.021*\"identifi\" + 0.021*\"method\" + 0.021*\"experi\" + 0.021*\"magnesium\" + 0.021*\"ether\" + 0.021*\"describ\"\n",
      "2018-07-18 18:52:32,154 : INFO : topic #216 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,155 : INFO : topic #46 (0.004): 0.001*\"eye\" + 0.001*\"compound\" + 0.001*\"flicker\" + 0.001*\"erg\" + 0.001*\"frequenc\" + 0.001*\"fusion\" + 0.001*\"ocellu\" + 0.001*\"form\" + 0.001*\"sensit\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:32,157 : INFO : topic #169 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,157 : INFO : topic diff=inf, rho=0.144338\n",
      "2018-07-18 18:52:32,226 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:32,229 : INFO : PROGRESS: pass 47, at document #58/58\n",
      "2018-07-18 18:52:32,298 : INFO : topic #117 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,299 : INFO : topic #170 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,301 : INFO : topic #211 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,302 : INFO : topic #169 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,302 : INFO : topic #214 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,305 : INFO : topic diff=inf, rho=0.142857\n",
      "2018-07-18 18:52:32,374 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:32,378 : INFO : PROGRESS: pass 48, at document #58/58\n",
      "2018-07-18 18:52:32,447 : INFO : topic #126 (0.004): 0.001*\"gland\" + 0.001*\"secret\" + 0.001*\"discharg\" + 0.001*\"function\" + 0.001*\"hypopharyng\" + 0.001*\"phase\" + 0.001*\"1960\" + 0.001*\"dri\" + 0.001*\"insolubl\" + 0.001*\"mandibular\"\n",
      "2018-07-18 18:52:32,448 : INFO : topic #7 (0.004): 0.001*\"nutrit\" + 0.001*\"queen\" + 0.001*\"factor\" + 0.001*\"gut\" + 0.001*\"major\" + 0.001*\"prepar\" + 0.001*\"cast\" + 0.001*\"establish\" + 0.001*\"convers\" + 0.001*\"reserv\"\n",
      "2018-07-18 18:52:32,450 : INFO : topic #102 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,451 : INFO : topic #122 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,453 : INFO : topic #1 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,454 : INFO : topic diff=inf, rho=0.141421\n",
      "2018-07-18 18:52:32,523 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:32,525 : INFO : PROGRESS: pass 49, at document #58/58\n",
      "2018-07-18 18:52:32,595 : INFO : topic #172 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,598 : INFO : topic #192 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,598 : INFO : topic #27 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,599 : INFO : topic #36 (0.004): 0.051*\"extract\" + 0.032*\"prepar\" + 0.025*\"type\" + 0.025*\"bodi\" + 0.019*\"compon\" + 0.019*\"allergen\" + 0.019*\"whole\" + 0.019*\"determin\" + 0.019*\"venom\" + 0.013*\"muscl\"\n",
      "2018-07-18 18:52:32,601 : INFO : topic #183 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,602 : INFO : topic diff=inf, rho=0.140028\n",
      "2018-07-18 18:52:32,671 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:32,674 : INFO : PROGRESS: pass 50, at document #58/58\n",
      "2018-07-18 18:52:32,747 : INFO : topic #33 (0.004): 0.001*\"nutrit\" + 0.001*\"establish\" + 0.001*\"cast\" + 0.001*\"factor\" + 0.001*\"phase\" + 0.001*\"larval\" + 0.001*\"relat\" + 0.001*\"fourth\" + 0.001*\"initi\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:32,750 : INFO : topic #131 (0.004): 0.063*\"attract\" + 0.063*\"moth\" + 0.032*\"americana\" + 0.032*\"isol\" + 0.032*\"bombyx\" + 0.032*\"pine\" + 0.032*\"1965\" + 0.032*\"terrestri\" + 0.032*\"mate\" + 0.032*\"silkworm\"\n",
      "2018-07-18 18:52:32,752 : INFO : topic #15 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,753 : INFO : topic #69 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,755 : INFO : topic #10 (0.004): 0.068*\"paralysi\" + 0.054*\"viru\" + 0.041*\"particl\" + 0.041*\"healthi\" + 0.041*\"cbpv\" + 0.027*\"chronic\" + 0.027*\"acut\" + 0.027*\"day\" + 0.027*\"abpv\" + 0.027*\"infect\"\n",
      "2018-07-18 18:52:32,756 : INFO : topic diff=inf, rho=0.138675\n",
      "2018-07-18 18:52:32,825 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:32,828 : INFO : PROGRESS: pass 51, at document #58/58\n",
      "2018-07-18 18:52:32,898 : INFO : topic #128 (0.004): 0.001*\"site\" + 0.001*\"old\" + 0.001*\"first\" + 0.001*\"new\" + 0.001*\"coloni\" + 0.001*\"visit\" + 0.001*\"return\" + 0.001*\"distanc\" + 0.001*\"move\" + 0.001*\"third\"\n",
      "2018-07-18 18:52:32,900 : INFO : topic #9 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,901 : INFO : topic #154 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,901 : INFO : topic #64 (0.004): 0.001*\"line\" + 0.001*\"larva\" + 0.001*\"virul\" + 0.001*\"resist\" + 0.001*\"suscept\" + 0.001*\"passag\" + 0.001*\"serial\" + 0.001*\"strain\" + 0.001*\"select\" + 0.001*\"spore\"\n",
      "2018-07-18 18:52:32,904 : INFO : topic #20 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:32,907 : INFO : topic diff=inf, rho=0.137361\n",
      "2018-07-18 18:52:32,979 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:32,982 : INFO : PROGRESS: pass 52, at document #58/58\n",
      "2018-07-18 18:52:33,052 : INFO : topic #193 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,053 : INFO : topic #181 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,055 : INFO : topic #13 (0.004): 0.001*\"spore\" + 0.001*\"line\" + 0.001*\"remov\" + 0.001*\"bacillu\" + 0.001*\"van\" + 0.001*\"cereu\" + 0.001*\"thuringiensi\" + 0.001*\"rapid\" + 0.001*\"measur\" + 0.001*\"foregut\"\n",
      "2018-07-18 18:52:33,056 : INFO : topic #79 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,058 : INFO : topic #163 (0.004): 0.078*\"cytochrom\" + 0.065*\"growth\" + 0.039*\"muscl\" + 0.039*\"progress\" + 0.039*\"wing\" + 0.039*\"pupal\" + 0.026*\"emerg\" + 0.026*\"discuss\" + 0.026*\"earli\" + 0.026*\"sarcosom\"\n",
      "2018-07-18 18:52:33,059 : INFO : topic diff=inf, rho=0.136083\n",
      "2018-07-18 18:52:33,131 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:33,134 : INFO : PROGRESS: pass 53, at document #58/58\n",
      "2018-07-18 18:52:33,201 : INFO : topic #159 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,204 : INFO : topic #199 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,207 : INFO : topic #144 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,209 : INFO : topic #114 (0.004): 0.029*\"specif\" + 0.029*\"physiolog\" + 0.029*\"identifi\" + 0.029*\"fed\" + 0.029*\"right\" + 0.029*\"societi\" + 0.029*\"abdomen\" + 0.029*\"compound\" + 0.029*\"form\" + 0.029*\"rapid\"\n",
      "2018-07-18 18:52:33,211 : INFO : topic #25 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,213 : INFO : topic diff=inf, rho=0.134840\n",
      "2018-07-18 18:52:33,283 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:33,285 : INFO : PROGRESS: pass 54, at document #58/58\n",
      "2018-07-18 18:52:33,355 : INFO : topic #109 (0.004): 0.107*\"toxic\" + 0.054*\"temperatur\" + 0.036*\"piperonyl\" + 0.036*\"butoxid\" + 0.036*\"carbam\" + 0.036*\"insecticid\" + 0.036*\"suggest\" + 0.036*\"time\" + 0.036*\"applic\" + 0.036*\"mechan\"\n",
      "2018-07-18 18:52:33,358 : INFO : topic #153 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,359 : INFO : topic #140 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,361 : INFO : topic #132 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,362 : INFO : topic #92 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,365 : INFO : topic diff=inf, rho=0.133631\n",
      "2018-07-18 18:52:33,433 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:33,437 : INFO : PROGRESS: pass 55, at document #58/58\n",
      "2018-07-18 18:52:33,506 : INFO : topic #64 (0.004): 0.001*\"line\" + 0.001*\"larva\" + 0.001*\"virul\" + 0.001*\"resist\" + 0.001*\"suscept\" + 0.001*\"passag\" + 0.001*\"serial\" + 0.001*\"strain\" + 0.001*\"select\" + 0.001*\"spore\"\n",
      "2018-07-18 18:52:33,507 : INFO : topic #8 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,509 : INFO : topic #148 (0.004): 0.064*\"cell\" + 0.064*\"veget\" + 0.043*\"dosag\" + 0.043*\"varieti\" + 0.043*\"thuringiensi\" + 0.043*\"toxic\" + 0.021*\"type\" + 0.021*\"though\" + 0.021*\"produc\" + 0.021*\"prepar\"\n",
      "2018-07-18 18:52:33,510 : INFO : topic #100 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,513 : INFO : topic #118 (0.004): 0.001*\"cytochrom\" + 0.001*\"progress\" + 0.001*\"growth\" + 0.001*\"wing\" + 0.001*\"pupal\" + 0.001*\"muscl\" + 0.001*\"sarcosom\" + 0.001*\"flight\" + 0.001*\"associ\" + 0.001*\"period\"\n",
      "2018-07-18 18:52:33,513 : INFO : topic diff=inf, rho=0.132453\n",
      "2018-07-18 18:52:33,584 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:33,585 : INFO : PROGRESS: pass 56, at document #58/58\n",
      "2018-07-18 18:52:33,657 : INFO : topic #186 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,660 : INFO : topic #160 (0.004): 0.044*\"salivari\" + 0.044*\"tongu\" + 0.044*\"process\" + 0.044*\"intak\" + 0.044*\"account\" + 0.044*\"discharg\" + 0.044*\"1964\" + 0.044*\"retract\" + 0.044*\"royal\" + 0.044*\"entomolog\"\n",
      "2018-07-18 18:52:33,661 : INFO : topic #157 (0.004): 0.088*\"prepar\" + 0.044*\"test\" + 0.044*\"respect\" + 0.044*\"108\" + 0.044*\"verlag\" + 0.044*\"107\" + 0.044*\"100\" + 0.044*\"appli\" + 0.044*\"commerci\" + 0.044*\"bacillu\"\n",
      "2018-07-18 18:52:33,663 : INFO : topic #193 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,664 : INFO : topic #106 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,667 : INFO : topic diff=inf, rho=0.131306\n",
      "2018-07-18 18:52:33,742 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:33,743 : INFO : PROGRESS: pass 57, at document #58/58\n",
      "2018-07-18 18:52:33,812 : INFO : topic #21 (0.004): 0.001*\"insemin\" + 0.001*\"semen\" + 0.001*\"vitro\" + 0.001*\"experiment\" + 0.001*\"fertil\" + 0.001*\"queen\" + 0.001*\"treatment\" + 0.001*\"day\" + 0.001*\"variou\" + 0.001*\"ordinari\"\n",
      "2018-07-18 18:52:33,813 : INFO : topic #218 (0.004): 0.072*\"semen\" + 0.072*\"insemin\" + 0.036*\"ship\" + 0.036*\"artifici\" + 0.036*\"describ\" + 0.036*\"egg\" + 0.036*\"fertil\" + 0.036*\"mail\" + 0.036*\"ordinari\" + 0.036*\"vitro\"\n",
      "2018-07-18 18:52:33,815 : INFO : topic #117 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,816 : INFO : topic #69 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,818 : INFO : topic #212 (0.004): 0.122*\"protein\" + 0.074*\"venom\" + 0.049*\"differ\" + 0.049*\"demonstr\" + 0.025*\"1965\" + 0.025*\"mean\" + 0.025*\"pure\" + 0.025*\"content\" + 0.025*\"extract\" + 0.025*\"incorpor\"\n",
      "2018-07-18 18:52:33,819 : INFO : topic diff=inf, rho=0.130189\n",
      "2018-07-18 18:52:33,892 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:33,897 : INFO : PROGRESS: pass 58, at document #58/58\n",
      "2018-07-18 18:52:33,967 : INFO : topic #81 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,970 : INFO : topic #202 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:33,971 : INFO : topic #78 (0.004): 0.001*\"extract\" + 0.001*\"prepar\" + 0.001*\"cocoon\" + 0.001*\"bodi\" + 0.001*\"type\" + 0.001*\"venom\" + 0.001*\"determin\" + 0.001*\"larva\" + 0.001*\"allergen\" + 0.001*\"whole\"\n",
      "2018-07-18 18:52:33,973 : INFO : topic #34 (0.004): 0.040*\"queen\" + 0.040*\"group\" + 0.040*\"publish\" + 0.040*\"egg\" + 0.027*\"structur\" + 0.027*\"cell\" + 0.027*\"form\" + 0.027*\"materi\" + 0.027*\"natur\" + 0.027*\"pore\"\n",
      "2018-07-18 18:52:33,976 : INFO : topic #120 (0.004): 0.042*\"paralysi\" + 0.042*\"mite\" + 0.042*\"spray\" + 0.042*\"suspens\" + 0.042*\"pathogen\" + 0.042*\"normal\" + 0.042*\"acarapi\" + 0.042*\"suscept\" + 0.042*\"infest\" + 0.042*\"pseudomona\"\n",
      "2018-07-18 18:52:33,976 : INFO : topic diff=inf, rho=0.129099\n",
      "2018-07-18 18:52:34,052 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:34,055 : INFO : PROGRESS: pass 59, at document #58/58\n",
      "2018-07-18 18:52:34,128 : INFO : topic #209 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,128 : INFO : topic #213 (0.004): 0.001*\"normal\" + 0.001*\"paralysi\" + 0.001*\"chronic\" + 0.001*\"cbpv\" + 0.001*\"natur\" + 0.001*\"viru\" + 0.001*\"inject\" + 0.001*\"mean\" + 0.001*\"pass\" + 0.001*\"cage\"\n",
      "2018-07-18 18:52:34,130 : INFO : topic #97 (0.004): 0.144*\"queen\" + 0.115*\"attract\" + 0.057*\"gland\" + 0.057*\"virgin\" + 0.057*\"mate\" + 0.057*\"secret\" + 0.029*\"termin\" + 0.029*\"rapid\" + 0.029*\"old\" + 0.029*\"mandibular\"\n",
      "2018-07-18 18:52:34,131 : INFO : topic #56 (0.004): 0.048*\"label\" + 0.048*\"acet\" + 0.048*\"cell\" + 0.039*\"fat\" + 0.039*\"acid\" + 0.039*\"feed\" + 0.029*\"uniformli\" + 0.029*\"wax\" + 0.029*\"compon\" + 0.029*\"origin\"\n",
      "2018-07-18 18:52:34,132 : INFO : topic #196 (0.004): 0.001*\"cast\" + 0.001*\"factor\" + 0.001*\"nutrit\" + 0.001*\"phase\" + 0.001*\"larval\" + 0.001*\"establish\" + 0.001*\"relat\" + 0.001*\"dimorph\" + 0.001*\"differ\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:34,134 : INFO : topic diff=inf, rho=0.128037\n",
      "2018-07-18 18:52:34,207 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:34,210 : INFO : PROGRESS: pass 60, at document #58/58\n",
      "2018-07-18 18:52:34,285 : INFO : topic #217 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,286 : INFO : topic #19 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,286 : INFO : topic #26 (0.004): 0.001*\"sarcosom\" + 0.001*\"mixtur\" + 0.001*\"oxid\" + 0.001*\"reaction\" + 0.001*\"describ\" + 0.001*\"incub\" + 0.001*\"cytochrom\" + 0.001*\"effici\" + 0.001*\"concentr\" + 0.001*\"addit\"\n",
      "2018-07-18 18:52:34,288 : INFO : topic #221 (0.004): 0.102*\"sternit\" + 0.068*\"size\" + 0.051*\"measur\" + 0.051*\"abdomin\" + 0.051*\"width\" + 0.051*\"length\" + 0.034*\"microscop\" + 0.034*\"differ\" + 0.017*\"made\" + 0.017*\"franci\"\n",
      "2018-07-18 18:52:34,289 : INFO : topic #87 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,290 : INFO : topic diff=inf, rho=0.127000\n",
      "2018-07-18 18:52:34,367 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:34,368 : INFO : PROGRESS: pass 61, at document #58/58\n",
      "2018-07-18 18:52:34,440 : INFO : topic #46 (0.004): 0.001*\"eye\" + 0.001*\"compound\" + 0.001*\"flicker\" + 0.001*\"erg\" + 0.001*\"frequenc\" + 0.001*\"fusion\" + 0.001*\"ocellu\" + 0.001*\"form\" + 0.001*\"sensit\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:34,441 : INFO : topic #147 (0.004): 0.001*\"cocoon\" + 0.001*\"secret\" + 0.001*\"gland\" + 0.001*\"materi\" + 0.001*\"larva\" + 0.001*\"discharg\" + 0.001*\"made\" + 0.001*\"hypopharyng\" + 0.001*\"queen\" + 0.001*\"respect\"\n",
      "2018-07-18 18:52:34,443 : INFO : topic #81 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,444 : INFO : topic #22 (0.004): 0.001*\"lay\" + 0.001*\"worker\" + 0.001*\"queen\" + 0.001*\"day\" + 0.001*\"spermatheca\" + 0.001*\"larg\" + 0.001*\"remov\" + 0.001*\"anatom\" + 0.001*\"dequeen\" + 0.001*\"reject\"\n",
      "2018-07-18 18:52:34,446 : INFO : topic #42 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,447 : INFO : topic diff=inf, rho=0.125988\n",
      "2018-07-18 18:52:34,516 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:34,519 : INFO : PROGRESS: pass 62, at document #58/58\n",
      "2018-07-18 18:52:34,592 : INFO : topic #36 (0.004): 0.051*\"extract\" + 0.032*\"prepar\" + 0.025*\"type\" + 0.025*\"bodi\" + 0.019*\"compon\" + 0.019*\"determin\" + 0.019*\"venom\" + 0.019*\"allergen\" + 0.019*\"whole\" + 0.013*\"test\"\n",
      "2018-07-18 18:52:34,594 : INFO : topic #112 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,595 : INFO : topic #148 (0.004): 0.064*\"cell\" + 0.064*\"veget\" + 0.043*\"dosag\" + 0.043*\"varieti\" + 0.043*\"thuringiensi\" + 0.043*\"toxic\" + 0.021*\"type\" + 0.021*\"though\" + 0.021*\"produc\" + 0.021*\"prepar\"\n",
      "2018-07-18 18:52:34,596 : INFO : topic #198 (0.004): 0.072*\"fell\" + 0.072*\"earli\" + 0.072*\"thu\" + 0.072*\"relationship\" + 0.072*\"possibl\" + 0.072*\"temper\" + 0.072*\"induc\" + 0.072*\"summer\" + 0.072*\"cup\" + 0.000*\"forag\"\n",
      "2018-07-18 18:52:34,598 : INFO : topic #69 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,599 : INFO : topic diff=inf, rho=0.125000\n",
      "2018-07-18 18:52:34,668 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:34,670 : INFO : PROGRESS: pass 63, at document #58/58\n",
      "2018-07-18 18:52:34,740 : INFO : topic #182 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,740 : INFO : topic #78 (0.004): 0.001*\"extract\" + 0.001*\"prepar\" + 0.001*\"cocoon\" + 0.001*\"bodi\" + 0.001*\"type\" + 0.001*\"venom\" + 0.001*\"determin\" + 0.001*\"larva\" + 0.001*\"allergen\" + 0.001*\"whole\"\n",
      "2018-07-18 18:52:34,743 : INFO : topic #23 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,744 : INFO : topic #35 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,746 : INFO : topic #216 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,746 : INFO : topic diff=inf, rho=0.124035\n",
      "2018-07-18 18:52:34,815 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:34,819 : INFO : PROGRESS: pass 64, at document #58/58\n",
      "2018-07-18 18:52:34,888 : INFO : topic #187 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,891 : INFO : topic #66 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:34,894 : INFO : topic #177 (0.004): 0.140*\"viru\" + 0.056*\"tissu\" + 0.056*\"cbpv\" + 0.028*\"locat\" + 0.028*\"compar\" + 0.028*\"muscl\" + 0.028*\"chronic\" + 0.028*\"reveal\" + 0.028*\"healthi\" + 0.028*\"thin\"\n",
      "2018-07-18 18:52:34,894 : INFO : topic #212 (0.004): 0.122*\"protein\" + 0.074*\"venom\" + 0.049*\"differ\" + 0.049*\"demonstr\" + 0.025*\"1965\" + 0.025*\"mean\" + 0.025*\"pure\" + 0.025*\"content\" + 0.025*\"extract\" + 0.025*\"incorpor\"\n",
      "2018-07-18 18:52:34,895 : INFO : topic #7 (0.004): 0.001*\"nutrit\" + 0.001*\"queen\" + 0.001*\"factor\" + 0.001*\"gut\" + 0.001*\"major\" + 0.001*\"prepar\" + 0.001*\"cast\" + 0.001*\"establish\" + 0.001*\"reserv\" + 0.001*\"convers\"\n",
      "2018-07-18 18:52:34,897 : INFO : topic diff=inf, rho=0.123091\n",
      "2018-07-18 18:52:34,963 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:34,966 : INFO : PROGRESS: pass 65, at document #58/58\n",
      "2018-07-18 18:52:35,036 : INFO : topic #91 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,038 : INFO : topic #111 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,039 : INFO : topic #215 (0.004): 0.001*\"eye\" + 0.001*\"compound\" + 0.001*\"flicker\" + 0.001*\"erg\" + 0.001*\"fusion\" + 0.001*\"sensit\" + 0.001*\"frequenc\" + 0.001*\"wave\" + 0.001*\"suggest\" + 0.001*\"ocellu\"\n",
      "2018-07-18 18:52:35,042 : INFO : topic #27 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,043 : INFO : topic #181 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,045 : INFO : topic diff=inf, rho=0.122169\n",
      "2018-07-18 18:52:35,114 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:35,117 : INFO : PROGRESS: pass 66, at document #58/58\n",
      "2018-07-18 18:52:35,186 : INFO : topic #217 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,187 : INFO : topic #182 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,187 : INFO : topic #102 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,190 : INFO : topic #34 (0.004): 0.040*\"queen\" + 0.040*\"group\" + 0.040*\"publish\" + 0.040*\"egg\" + 0.027*\"structur\" + 0.027*\"cell\" + 0.027*\"form\" + 0.027*\"materi\" + 0.027*\"natur\" + 0.027*\"pore\"\n",
      "2018-07-18 18:52:35,190 : INFO : topic #123 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,193 : INFO : topic diff=inf, rho=0.121268\n",
      "2018-07-18 18:52:35,263 : INFO : -7.317 per-word bound, 159.5 perplexity estimate based on a held-out corpus of 58 documents with 3027 words\n",
      "2018-07-18 18:52:35,266 : INFO : PROGRESS: pass 67, at document #58/58\n",
      "2018-07-18 18:52:35,338 : INFO : topic #70 (0.004): 0.072*\"paralysi\" + 0.072*\"suffer\" + 0.072*\"viru\" + 0.048*\"infect\" + 0.048*\"britain\" + 0.048*\"itali\" + 0.024*\"austria\" + 0.024*\"etiolog\" + 0.024*\"linnaeu\" + 0.024*\"canada\"\n",
      "2018-07-18 18:52:35,338 : INFO : topic #7 (0.004): 0.001*\"nutrit\" + 0.001*\"queen\" + 0.001*\"factor\" + 0.001*\"gut\" + 0.001*\"major\" + 0.001*\"prepar\" + 0.001*\"cast\" + 0.001*\"establish\" + 0.001*\"reserv\" + 0.001*\"convers\"\n",
      "2018-07-18 18:52:35,342 : INFO : topic #191 (0.004): 0.071*\"sarcosom\" + 0.041*\"oxid\" + 0.041*\"reaction\" + 0.041*\"mixtur\" + 0.030*\"stimul\" + 0.030*\"respiratori\" + 0.030*\"addit\" + 0.030*\"incub\" + 0.030*\"adp\" + 0.020*\"isol\"\n",
      "2018-07-18 18:52:35,344 : INFO : topic #185 (0.004): 0.001*\"pure\" + 0.001*\"optimum\" + 0.001*\"venom\" + 0.001*\"underneath\" + 0.001*\"thousand\" + 0.001*\"shock\" + 0.001*\"quantiti\" + 0.001*\"employ\" + 0.001*\"provid\" + 0.001*\"milk\"\n",
      "2018-07-18 18:52:35,345 : INFO : topic #184 (0.004): 0.001*\"nutrit\" + 0.001*\"phase\" + 0.001*\"factor\" + 0.001*\"cast\" + 0.001*\"establish\" + 0.001*\"larval\" + 0.001*\"day\" + 0.001*\"differ\" + 0.001*\"fourth\" + 0.001*\"suggest\"\n",
      "2018-07-18 18:52:35,345 : INFO : topic diff=inf, rho=0.120386\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4eaa142b4cae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%(asctime)s : %(levelname)s : %(message)s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumberOfTopics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mtopics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtop_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\USER\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\USER\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreallen\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_no\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meval_every\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumworkers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\USER\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36mlog_perplexity\u001b[1;34m(self, chunk, total_docs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mperwordbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         logger.info(\n\u001b[0;32m    581\u001b[0m             \u001b[1;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\USER\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36mbound\u001b[1;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[0;32m    815\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bound: at document #%i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m                 \u001b[0mgammad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\USER\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    502\u001b[0m                     \u001b[0mconverged\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgammad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mgammad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from difflib import SequenceMatcher\n",
    "size = 0\n",
    "start = 0\n",
    "import os\n",
    "occurences = None\n",
    "try:\n",
    "    for i in range(0,len(selections)):\n",
    "        keyphraseTracker = api.KeyWordTracker()\n",
    "        size += len(selections[i])\n",
    "        if size >=50:\n",
    "            selection = api.flaten(selections[start:i+1])\n",
    "            for abstr in selection:\n",
    "                phrases = [k.strip() for k in  abstr.keywords.split(\";\")]\n",
    "                keyPhrases = []\n",
    "                for phr in phrases:\n",
    "                    words = [ps.stem(w) if all(ord(c) < 128 for c in w) else None for w in phr.split(\" \")]\n",
    "                    string = \"\"\n",
    "                    for w in words:\n",
    "                        if w != None:\n",
    "                            string = string +\" \"+ w\n",
    "                    string = string.strip()\n",
    "                    if len(string) > 2:\n",
    "                        keyPhrases.append(string)\n",
    "                    for kph in keyPhrases:    \n",
    "                        keyphraseTracker.track(kph,abstr.date.year)\n",
    "                        keyphraseTracker.registerCoOccurrences(kph,keyPhrases)\n",
    "            #continue to next section\n",
    "            corpus = createCorpus(selection)\n",
    "            path = docs+'GephiFiles/'+str(selection[0].date.year)+'/'\n",
    "            try:\n",
    "                os.makedirs(path)\n",
    "                print \"made dirs\"\n",
    "            except:\n",
    "                #Already exists\n",
    "                pass\n",
    "            logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "            lda = models.ldamodel.LdaModel(corpus.corpus,id2word=corpus.id2word,num_topics=numberOfTopics,passes=passes)\n",
    "            topics = lda.top_topics(corpus=corpus.corpus,dictionary=corpus.id2word,topn=3)\n",
    "            \n",
    "            topics.sort(key=lambda k:k[1],reverse=True)\n",
    "            occurences = getResults(topics)\n",
    "            sortedVals = [sorted(occurences[0].values(),key=lambda k:k[\"occurences\"],reverse=True),occurences[1]]\n",
    "            #####Release some of this memory please and thank you\n",
    "            selection = None\n",
    "            #occurences = None\n",
    "            #####\n",
    "            exportResults(path,sortedVals,occurences[0])\n",
    "            size = 0\n",
    "            start = i+1\n",
    "    os.system(\"emailme \\\"Finished successfully!\\\"\")\n",
    "except Exception as e:\n",
    "    os.system(\"emailme \\\"Failed come check it out: \"+str(e)+\" \\\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above corpus shows the amount of times every word used in the documents is used in every indevidual document. Every word is represented by a token ID, the list of which can be found in \"words.dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-faefbcd59663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtopicOrganizingFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/topicorganization.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabstracts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabstracts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdocTopics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordTopics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphiValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtopicOrganizingFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myearOfAbstract\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtitleOfAbstract\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "# Sort the most interesting words per topic per document\n",
    "# This cell does not need to be run if only trying to create Top Nine terms per paper\n",
    "topicOrganizingFile = open(\"../data/topicorganization.tsv\",\"w\")\n",
    "for x in xrange(0,len(abstracts)):\n",
    "    doc = dictionary.doc2bow(abstracts[x].split())\n",
    "    docTopics, wordTopics, phiValues = lda.get_document_topics(doc, per_word_topics=True)\n",
    "    topicOrganizingFile.write(yearOfAbstract[x]+\"\\t\"+titleOfAbstract[x]+\"\\t\")\n",
    "    for y in xrange(0,min(3,len(docTopics))):\n",
    "        topicnumber = docTopics[y][0]\n",
    "        topicOrganizingFile.write(str(lda.show_topic(topicnumber))+\"\\t\")\n",
    "        #Sorts the word topics in decending order based on their greatest phi value\n",
    "        for z in xrange(0,len(phiValues)):\n",
    "            phiValues[z][1].sort(key=lambda q:q[1],reverse=True)\n",
    "        phiValues.sort(key=lambda q:q[1][0][1],reverse=True)\n",
    "        curindex=0\n",
    "        topwords = \"\"\n",
    "        for z in xrange(0,3):\n",
    "            while curindex<len(phiValues) and phiValues[curindex][1][0][0]!=topicnumber:\n",
    "                curindex+=1\n",
    "            if(curindex>=len(phiValues)):break\n",
    "            print len(phiValues)\n",
    "            print dictionary[phiValues[curindex][0]]\n",
    "            topwords+=str(dictionary[phiValues[curindex][0]].encode('utf-8').strip())+\" \"\n",
    "            curindex+=1\n",
    "        filter(lambda a:a[0]!=topicnumber,phiValues)\n",
    "        topicOrganizingFile.write(topwords+\"\\t\")\n",
    "    topicOrganizingFile.write(\"\\n\")\n",
    "topicOrganizingFile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicWords = []\n",
    "for i in range(0,numberOfTopics):\n",
    "    t = lda.get_topic_terms(i,50)\n",
    "    currentWordList = []\n",
    "    for x in t:\n",
    "        word = str(dictionary[x[0]])\n",
    "        if word not in currentWordList:\n",
    "            currentWordList.append(word)\n",
    "    topicWords.append(currentWordList)\n",
    "topicListFile = open(\"../data/TopicWords/List-\"+str(numberOfTopics)+\".txt\",\"w+\")\n",
    "for i in range(0,len(topicWords)):\n",
    "    topicListFile.write(\"Topic \"+str(i)+\":\\n\")\n",
    "    for j in topicWords[i]:\n",
    "        topicListFile.write(j+'\\n')\n",
    "    topicListFile.write('\\n')\n",
    "topicListFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes the top nine terms for each document\n",
    "\n",
    "topNineFile = open(\"../data/Docbow/TopNineTerms-\"+str(numberOfTopics)+\".tsv\",\"w\")\n",
    "for abstr in abstracts:\n",
    "    doc = dictionary.doc2bow(abstracts[2].split()) # Convert to bag of words format first\n",
    "    # Get the topics and words associated with each document\n",
    "    docTopics, wordTopics, phiValues = lda.get_document_topics(doc, per_word_topics=True)\n",
    "    topNineFile.write(yearOfAbstract[x]+\"\\t\"+abst+\"\\t\")\n",
    "    for z in xrange(0,len(phiValues)):\n",
    "        phiValues[z][1].sort(key=lambda q:q[1],reverse=True)\n",
    "    phiValues.sort(key=lambda q:q[1][0][1],reverse=True)\n",
    "    nineWords = \"\"\n",
    "    for x in phiValues[:15]:\n",
    "        nineWords+= dictionary[x[0]] + \" \"\n",
    "    topNineFile.write(nineWords.encode('utf-8')+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = api.flaten(yearlyCorpora[0])\n",
    "first.sort(key=lambda x: x[0])\n",
    "print api.binarySearch(first,0,lambda x: x[0])\n",
    "print first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = occurences.values()\n",
    "vals.sort(key=lambda x:x['occurences'],reverse=True)\n",
    "print vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedVals = sorted(occurences.values(),key=lambda k:k[\"tag\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1985: 1, 2001: 1, 2004: 1, 2005: 1, 1999: 1}\n"
     ]
    }
   ],
   "source": [
    "y = keyphraseTracker.words[ps.stem(\"colony\")]\n",
    "print y.years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
